{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20df669-4eba-4c0c-b268-11de573b5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda config --add channels conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113597c5-12a4-48d3-a8af-7e9c7e4cefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install montreal-forced-aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde4c222-4d7d-4833-bd2f-980b90acaf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f951ee5-a54b-4b1d-9176-d8eef078ba10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(shutil.which(\"mfa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53fc2149-a8e3-44a6-a80b-5717d1af5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/DELL/Downloads/acoustic_framework-main-2/Normal_Hannah_DDK.wav\n",
      "Saved TextGrid to: /Users/DELL/Downloads/acoustic_framework-main-2/Normal_Hannah_DDK.TextGrid\n",
      "Processed /Users/DELL/Downloads/acoustic_framework-main-2/Normal_Hannah_DDK.wav\n",
      "DDK Rate: 69.02 triads/minute\n",
      "TextGrid saved to: /Users/DELL/Downloads/acoustic_framework-main-2/Normal_Hannah_DDK.TextGrid\n",
      "\n",
      "Complete analysis saved to: /Users/DELL/Downloads/acoustic_framework-main-2/ddk_analysis_complete.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Automated DDK (Diadochokinetic) Rate Analyzer for Jupyter Notebook\n",
    "# This script automatically processes \"puh-tuh-kuh\" speech samples\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import parselmouth\n",
    "from parselmouth.praat import call\n",
    "import pandas as pd\n",
    "import json\n",
    "import tempfile\n",
    "import shutil\n",
    "from praatio import textgrid\n",
    "\n",
    "# --- Configuration ---\n",
    "DEFAULT_SAMPLE_RATE = 16000  # Hz\n",
    "MONTREAL_FORCED_ALIGNER_PATH = \"/Users/DELL/anaconda3/envs/your_mfa_env\"  # Update with your path\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def create_dictionary_file(temp_dir):\n",
    "    \"\"\"Create a dictionary file for the forced aligner with our target syllables.\"\"\"\n",
    "    dictionary_content = \"\"\"\n",
    "PUH P UH\n",
    "TUH T UH\n",
    "KUH K UH\n",
    "\"\"\"\n",
    "    dict_path = os.path.join(temp_dir, \"dict.txt\")\n",
    "    with open(dict_path, \"w\") as f:\n",
    "        f.write(dictionary_content.strip())\n",
    "    return dict_path\n",
    "\n",
    "def create_corpus_file(temp_dir):\n",
    "    \"\"\"Create a corpus file for the forced aligner.\"\"\"\n",
    "    corpus_content = \"PUH TUH KUH PUH TUH KUH PUH TUH KUH\"\n",
    "    corpus_path = os.path.join(temp_dir, \"corpus.txt\")\n",
    "    with open(corpus_path, \"w\") as f:\n",
    "        f.write(corpus_content)\n",
    "    return corpus_path\n",
    "\n",
    "\n",
    "def detect_syllables_forced(wav_file, num_syllables=9):\n",
    "    \"\"\"Force syllable detection by dividing the audio into equal segments\"\"\"\n",
    "    # Load audio\n",
    "    y, sr = librosa.load(wav_file, sr=None)\n",
    "    duration = len(y) / sr\n",
    "    \n",
    "    # Find where the actual speech begins and ends\n",
    "    # Use amplitude threshold to find non-silent regions\n",
    "    is_speech = np.abs(y) > 0.02  # Adjust threshold as needed\n",
    "    \n",
    "    # Find first and last speech samples\n",
    "    speech_indices = np.where(is_speech)[0]\n",
    "    if len(speech_indices) > 0:\n",
    "        first_speech = speech_indices[0] / sr\n",
    "        last_speech = speech_indices[-1] / sr\n",
    "    else:\n",
    "        # If no speech detected, use the whole file\n",
    "        first_speech = 0\n",
    "        last_speech = duration\n",
    "    \n",
    "    # Add small buffer\n",
    "    first_speech = max(0, first_speech - 0.1)\n",
    "    last_speech = min(duration, last_speech + 0.1)\n",
    "    \n",
    "    speech_duration = last_speech - first_speech\n",
    "    \n",
    "    # Divide speech duration into equal segments\n",
    "    segment_duration = speech_duration / num_syllables\n",
    "    \n",
    "    # Create boundaries\n",
    "    boundaries = []\n",
    "    for i in range(num_syllables):\n",
    "        start = first_speech + i * segment_duration\n",
    "        end = start + segment_duration\n",
    "        boundaries.append((start, end))\n",
    "    \n",
    "    # For classification, assign a repeating pattern of \"puh\", \"tuh\", \"kuh\"\n",
    "    classified = []\n",
    "    labels = [\"puh\", \"tuh\", \"kuh\"] * (num_syllables // 3 + 1)\n",
    "    \n",
    "    for i, (start, end) in enumerate(boundaries):\n",
    "        if i < len(labels):\n",
    "            classified.append((start, end, labels[i]))\n",
    "    \n",
    "    return classified\n",
    "\n",
    "def classify_syllables(wav_file, boundaries):\n",
    "    \"\"\"\n",
    "    Classify each syllable as 'puh', 'tuh', or 'kuh' based on acoustic features.\n",
    "    \n",
    "    Parameters:\n",
    "    wav_file (str): Path to the WAV file\n",
    "    boundaries (list): List of (start_time, end_time) tuples\n",
    "    \n",
    "    Returns:\n",
    "    list: List of (start_time, end_time, label) tuples\n",
    "    \"\"\"\n",
    "    print(\"Loading audio for classification...\")\n",
    "    y, sr = librosa.load(wav_file, sr=None)\n",
    "    \n",
    "    # Create a Praat Sound object\n",
    "    try:\n",
    "        snd = parselmouth.Sound(wav_file)\n",
    "        print(f\"Successfully loaded Sound object with duration: {snd.xmax - snd.xmin:.2f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading Sound object: {e}\")\n",
    "        snd = None\n",
    "    \n",
    "    classified_syllables = []\n",
    "    \n",
    "    # Define pattern for rotating through puh-tuh-kuh\n",
    "    pattern_labels = [\"puh\", \"tuh\", \"kuh\"]\n",
    "    pattern_index = 0\n",
    "    \n",
    "    for i, (start, end) in enumerate(boundaries):\n",
    "        try:\n",
    "            # Extract this segment\n",
    "            segment = y[int(start * sr):int(end * sr)]\n",
    "            \n",
    "            if len(segment) > 0:\n",
    "                # Use spectral centroid for classification\n",
    "                centroid = librosa.feature.spectral_centroid(y=segment, sr=sr)[0].mean()\n",
    "                \n",
    "                # SIMPLIFIED CLASSIFICATION: \n",
    "                # Option 1: Use spectral features\n",
    "                if snd is not None:\n",
    "                    try:\n",
    "                        # Get the segment\n",
    "                        segment_duration = end - start\n",
    "                        if segment_duration < 0.05:  # Skip very short segments\n",
    "                            continue\n",
    "                            \n",
    "                        # Use simpler classification approach\n",
    "                        if centroid < 1000:  # Lower frequency for 'p'\n",
    "                            label = \"puh\"\n",
    "                        elif centroid < 2000:  # Mid frequency for 't'\n",
    "                            label = \"tuh\"\n",
    "                        else:  # Higher frequency for 'k'\n",
    "                            label = \"kuh\"\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing segment {i}: {e}\")\n",
    "                        # Fallback to pattern-based labeling\n",
    "                        label = pattern_labels[pattern_index % 3]\n",
    "                else:\n",
    "                    # Option 2: Fallback to pattern-based approach (assume perfect repetition)\n",
    "                    label = pattern_labels[pattern_index % 3]\n",
    "                \n",
    "                classified_syllables.append((start, end, label))\n",
    "                pattern_index += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error classifying syllable {i}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Classified {len(classified_syllables)} syllables\")\n",
    "    return classified_syllables\n",
    "\n",
    "def calculate_ddk_rate(syllables):\n",
    "    \"\"\"\n",
    "    Calculate the DDK rate from the syllable timings.\n",
    "    \n",
    "    Parameters:\n",
    "    syllables (list): List of (start_time, end_time, label) tuples\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary with DDK metrics\n",
    "    \"\"\"\n",
    "    if len(syllables) < 3:\n",
    "        return {\"ddk_rate\": 0, \"error\": \"Not enough syllables detected\"}\n",
    "    \n",
    "    # Group syllables into triads (puh-tuh-kuh)\n",
    "    triads = []\n",
    "    i = 0\n",
    "    \n",
    "    # First approach: Look for perfect sequences\n",
    "    while i <= len(syllables) - 3:\n",
    "        # Check if this is a valid puh-tuh-kuh sequence\n",
    "        if (syllables[i][2] == \"puh\" and \n",
    "            syllables[i+1][2] == \"tuh\" and \n",
    "            syllables[i+2][2] == \"kuh\"):\n",
    "            triads.append((syllables[i][0], syllables[i+2][1]))  # Start of puh to end of kuh\n",
    "            i += 3\n",
    "        else:\n",
    "            # Skip to next syllable if pattern doesn't match\n",
    "            i += 1\n",
    "    \n",
    "    # If no triads found with perfect matching, use a more lenient approach\n",
    "    if not triads and len(syllables) >= 3:\n",
    "        print(\"No perfect triads found, using sequential grouping\")\n",
    "        i = 0\n",
    "        while i <= len(syllables) - 3:\n",
    "            triads.append((syllables[i][0], syllables[i+2][1]))\n",
    "            i += 3\n",
    "    \n",
    "    if not triads:\n",
    "        return {\"ddk_rate\": 0, \"error\": \"No complete puh-tuh-kuh triads found\"}\n",
    "    \n",
    "    # Calculate durations of each triad\n",
    "    durations = [end - start for start, end in triads]\n",
    "    \n",
    "    # Calculate DDK metrics\n",
    "    avg_duration = np.mean(durations)\n",
    "    ddk_rate = 60 / avg_duration  # Triads per minute\n",
    "    \n",
    "    return {\n",
    "        \"ddk_rate\": ddk_rate,\n",
    "        \"avg_triad_duration\": avg_duration,\n",
    "        \"triad_count\": len(triads),\n",
    "        \"triads\": triads\n",
    "    }\n",
    "\n",
    "def create_textgrid(wav_file, syllables, ddk_metrics):\n",
    "    \"\"\"\n",
    "    Create a TextGrid file from the segmentation results.\n",
    "    \"\"\"\n",
    "    # Get audio duration\n",
    "    y, sr = librosa.load(wav_file, sr=None)\n",
    "    duration = len(y) / sr\n",
    "    \n",
    "    # Create TextGrid\n",
    "    tg = textgrid.Textgrid()\n",
    "    \n",
    "    # Add tiers\n",
    "    vowel_tier = textgrid.IntervalTier('vowel', [], 0, duration)\n",
    "    consonant_tier = textgrid.IntervalTier('consonant', [], 0, duration)\n",
    "    repetition_tier = textgrid.IntervalTier('reps', [], 0, duration)\n",
    "    full_tier = textgrid.IntervalTier('full', [], 0, duration)\n",
    "    \n",
    "    # Add intervals for each syllable\n",
    "    for i, (start, end, label) in enumerate(syllables):\n",
    "        # Estimate consonant vs vowel boundary (simplified)\n",
    "        cons_vowel_boundary = start + (end - start) * 0.3\n",
    "        \n",
    "        # Add to vowel tier\n",
    "        vowel_label = label[-2:]  # Get the vowel part (uh)\n",
    "        vowel_tier.insertEntry((cons_vowel_boundary, end, vowel_label))\n",
    "        \n",
    "        # Add to consonant tier\n",
    "        consonant_label = label[0]  # Get the consonant part (p, t, or k)\n",
    "        consonant_tier.insertEntry((start, cons_vowel_boundary, consonant_label))\n",
    "    \n",
    "    # Add repetition intervals (triads of puh-tuh-kuh)\n",
    "    if ddk_metrics.get(\"triads\"):\n",
    "        # Sort triads by start time to avoid overlaps\n",
    "        sorted_triads = sorted(ddk_metrics[\"triads\"], key=lambda x: x[0])\n",
    "        \n",
    "        for i, (start, end) in enumerate(sorted_triads):\n",
    "            # Make sure there's no overlap with previous triads\n",
    "            if i > 0 and start < sorted_triads[i-1][1]:\n",
    "                # Fix overlap by using the end of the previous triad as the start\n",
    "                start = sorted_triads[i-1][1] + 0.001  # Add a tiny gap\n",
    "            \n",
    "            if start < end:  # Only add if it's a valid interval\n",
    "                repetition_tier.insertEntry((start, end, f\"puhtuhkuh{i+1}\"))\n",
    "    \n",
    "    # Add DDK rate to full tier\n",
    "    full_tier.insertEntry((0, duration, f\"DDKrate: {ddk_metrics.get('ddk_rate', 0):.2f}\"))\n",
    "    \n",
    "    # Add tiers to TextGrid\n",
    "    try:\n",
    "        tg.addTier(vowel_tier)\n",
    "        tg.addTier(consonant_tier)\n",
    "        tg.addTier(repetition_tier)\n",
    "        tg.addTier(full_tier)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            tg.append(vowel_tier)\n",
    "            tg.append(consonant_tier)\n",
    "            tg.append(repetition_tier)\n",
    "            tg.append(full_tier)\n",
    "        except AttributeError:\n",
    "            tg.tiers = [vowel_tier, consonant_tier, repetition_tier, full_tier]\n",
    "    \n",
    "    return tg\n",
    "\n",
    " \n",
    "# --- Main Processing Function ---\n",
    "def process_audio_file(wav_file, output_dir=None, use_forced_alignment=False):\n",
    "    \"\"\"\n",
    "    Process a single audio file to analyze DDK rate.\n",
    "    \n",
    "    Parameters:\n",
    "    wav_file (str): Path to the WAV file\n",
    "    output_dir (str): Directory to save the output files\n",
    "    use_forced_alignment (bool): Whether to use forced alignment or acoustic-only analysis\n",
    "    \n",
    "    Returns:\n",
    "    dict: Results including DDK metrics and paths to output files\n",
    "    \"\"\"\n",
    "    print(f\"Processing file: {wav_file}\")\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.dirname(wav_file)\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(wav_file))[0]\n",
    "    textgrid_path = os.path.join(output_dir, f\"{base_name}.TextGrid\")\n",
    "    results_path = os.path.join(output_dir, f\"{base_name}_results.json\")\n",
    "    \n",
    "    # Make sure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process the file\n",
    "    try:\n",
    "        syllables = None\n",
    "        \n",
    "        # Try forced alignment if requested\n",
    "        if use_forced_alignment:\n",
    "            try:\n",
    "                with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                    aligned_textgrid = run_forced_alignment(wav_file, temp_dir)\n",
    "                    if aligned_textgrid and os.path.exists(aligned_textgrid):\n",
    "                        print(f\"Successfully created aligned TextGrid: {aligned_textgrid}\")\n",
    "                        # For now, fall back to acoustic detection\n",
    "                        syllables = None\n",
    "            except Exception as e:\n",
    "                print(f\"Forced alignment failed: {e}\")\n",
    "                syllables = None\n",
    "        \n",
    "        # Fall back to acoustic segmentation if needed\n",
    "        if syllables is None:\n",
    "            # Detect syllable boundaries\n",
    "            syllables = detect_syllables_forced(wav_file)\n",
    "        \n",
    "        # Calculate DDK rate\n",
    "        ddk_metrics = calculate_ddk_rate(syllables)\n",
    "        \n",
    "        # Create TextGrid\n",
    "        tg = create_textgrid(wav_file, syllables, ddk_metrics)\n",
    "        \n",
    "        # Save TextGrid\n",
    "        tg.save(textgrid_path, format=\"long_textgrid\", includeBlankSpaces=True)\n",
    "        print(f\"Saved TextGrid to: {textgrid_path}\")\n",
    "        \n",
    "        # Save results as JSON\n",
    "        with open(results_path, \"w\") as f:\n",
    "            json.dump({\n",
    "                \"wav_file\": wav_file,\n",
    "                \"ddk_metrics\": ddk_metrics,\n",
    "                \"syllable_count\": len(syllables),\n",
    "                \"textgrid_path\": textgrid_path\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        return {\n",
    "            \"wav_file\": wav_file,\n",
    "            \"ddk_metrics\": ddk_metrics,\n",
    "            \"textgrid_path\": textgrid_path,\n",
    "            \"results_path\": results_path\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Add this to the except block in process_audio_file:\n",
    "        return {\n",
    "            \"wav_file\": wav_file,\n",
    "            \"error\": str(e),\n",
    "            \"ddk_metrics\": {\"ddk_rate\": 0, \"error\": str(e)},  # Add this line\n",
    "            \"textgrid_path\": None\n",
    "        }\n",
    "        \n",
    "\n",
    "# --- Batch Processing Function ---\n",
    "def batch_process(input_dir, output_dir=None, use_forced_alignment=False):\n",
    "    \"\"\"\n",
    "    Process all WAV files in a directory.\n",
    "    \n",
    "    Parameters:\n",
    "    input_dir (str): Directory containing WAV files\n",
    "    output_dir (str): Directory to save the output files\n",
    "    use_forced_alignment (bool): Whether to use forced alignment\n",
    "    \n",
    "    Returns:\n",
    "    list: Results for each processed file\n",
    "    \"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = input_dir\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(\".wav\"):\n",
    "            wav_path = os.path.join(input_dir, filename)\n",
    "            result = process_audio_file(wav_path, output_dir, use_forced_alignment)\n",
    "            results.append(result)\n",
    "    \n",
    "    # Create a summary report\n",
    "    summary_path = os.path.join(output_dir, \"ddk_summary.csv\")\n",
    "    summary_data = []\n",
    "    \n",
    "    for result in results:\n",
    "        if \"error\" not in result:\n",
    "            summary_data.append({\n",
    "                \"filename\": os.path.basename(result[\"wav_file\"]),\n",
    "                \"ddk_rate\": result[\"ddk_metrics\"].get(\"ddk_rate\", 0),\n",
    "                \"triad_count\": result[\"ddk_metrics\"].get(\"triad_count\", 0),\n",
    "                \"avg_triad_duration\": result[\"ddk_metrics\"].get(\"avg_triad_duration\", 0)\n",
    "            })\n",
    "    \n",
    "    if summary_data:\n",
    "        pd.DataFrame(summary_data).to_csv(summary_path, index=False)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def extract_phonemes(textgrid_path):\n",
    "    \"\"\"\n",
    "    Extract individual phoneme information from a TextGrid file.\n",
    "    \n",
    "    Parameters:\n",
    "    textgrid_path (str): Path to the TextGrid file\n",
    "    \n",
    "    Returns:\n",
    "    list: List of dictionaries with phoneme information\n",
    "    \"\"\"\n",
    "    # Load the TextGrid\n",
    "    tg = textgrid.openTextgrid(textgrid_path, includeEmptyIntervals=False)\n",
    "    \n",
    "    # Get the consonant tier (typically Tier 1)\n",
    "    if len(tg.tiers) < 1:\n",
    "        print(f\"No consonant tier found in {textgrid_path}\")\n",
    "        return []\n",
    "    \n",
    "    consonant_tier = tg.tiers[1]  # Index 1 corresponds to the consonant tier\n",
    "    \n",
    "    # Extract phoneme information\n",
    "    phoneme_data = []\n",
    "    for interval in consonant_tier.entries:\n",
    "        label = interval[2].strip()  # Get the label (p, t, or k)\n",
    "        \n",
    "        if label in [\"p\", \"t\", \"k\"]:\n",
    "            start_time = interval[0]\n",
    "            end_time = interval[1]\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            # Determine which repetition this belongs to\n",
    "            # This requires looking at the pattern or using the repetition tier\n",
    "            repetition = determine_repetition(tg, start_time, end_time)\n",
    "            \n",
    "            phoneme_data.append({\n",
    "                \"Phoneme\": label,\n",
    "                \"StartTime\": start_time,\n",
    "                \"EndTime\": end_time,\n",
    "                \"Duration\": duration,\n",
    "                \"Repetition\": repetition\n",
    "            })\n",
    "    \n",
    "    return phoneme_data\n",
    "\n",
    "def determine_repetition(tg, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Determine which repetition a phoneme belongs to by checking the repetition tier.\n",
    "    \"\"\"\n",
    "    repetition_tier = tg.tiers[2]  # Index 2 corresponds to the repetition tier\n",
    "    \n",
    "    for interval in repetition_tier.entries:\n",
    "        rep_start, rep_end, rep_label = interval\n",
    "        \n",
    "        # Check if the phoneme falls within this repetition\n",
    "        if start_time >= rep_start and end_time <= rep_end:\n",
    "            # Extract the repetition number from the label (e.g., \"puhtuhkuh1\" -> \"1\")\n",
    "            rep_number = rep_label[-1] if rep_label[-1].isdigit() else \"0\"\n",
    "            return rep_number\n",
    "    \n",
    "    return \"0\"  # Default if not found in any repetition\n",
    "\n",
    "# --- Example usage code (uncomment to use) ---\n",
    "\n",
    "import json\n",
    "\n",
    "# For a single file:\n",
    "# Define your input and output paths\n",
    "wav_file = \"/Users/DELL/Downloads/acoustic_framework-main-2/Normal_Hannah_DDK.wav\"  # Replace with your actual file path\n",
    "output_dir = \"/Users/DELL/Downloads/acoustic_framework-main-2/\"  # Optional, replace or set to None\n",
    "\n",
    "# Process the file\n",
    "result = process_audio_file(\n",
    "    wav_file=wav_file,\n",
    "    output_dir=output_dir,\n",
    "    use_forced_alignment=False  # Set to False to skip alignment\n",
    ")\n",
    "\n",
    "# Print the basic results\n",
    "print(f\"Processed {wav_file}\")\n",
    "print(f\"DDK Rate: {result['ddk_metrics'].get('ddk_rate', 0):.2f} triads/minute\")\n",
    "print(f\"TextGrid saved to: {result['textgrid_path']}\")\n",
    "\n",
    "# Extract and analyze individual phonemes\n",
    "textgrid_path = result['textgrid_path']\n",
    "phoneme_data = extract_phonemes(textgrid_path)\n",
    "\n",
    "# Group by phoneme type\n",
    "phoneme_groups = {}\n",
    "for item in phoneme_data:\n",
    "    phoneme = item[\"Phoneme\"]\n",
    "    if phoneme not in phoneme_groups:\n",
    "        phoneme_groups[phoneme] = []\n",
    "    phoneme_groups[phoneme].append(item)\n",
    "\n",
    "# Create phoneme statistics\n",
    "phoneme_stats = {}\n",
    "for phoneme, items in phoneme_groups.items():\n",
    "    durations = [item[\"Duration\"] for item in items]\n",
    "    avg_duration = sum(durations) / len(durations) if durations else 0\n",
    "    phoneme_stats[phoneme] = {\n",
    "        \"count\": len(items),\n",
    "        \"avg_duration\": avg_duration,\n",
    "        \"instances\": items\n",
    "    }\n",
    "\n",
    "# Add phoneme data to the results dictionary\n",
    "result['phoneme_data'] = phoneme_data\n",
    "result['phoneme_stats'] = phoneme_stats\n",
    "\n",
    "# Save all results to a JSON file\n",
    "json_path = os.path.join(output_dir, \"ddk_analysis_complete.json\")\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(f\"\\nComplete analysis saved to: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfe344-a237-4ad9-aed4-65289b65535d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
