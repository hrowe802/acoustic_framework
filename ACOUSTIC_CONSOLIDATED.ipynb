{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b24320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praatio\n",
      "  Obtaining dependency information for praatio from https://files.pythonhosted.org/packages/c4/8e/eb83f93f0e46c5bfd20a3040eef7ccece8ac0703b06a500fb17a57627a2e/praatio-6.2.0-py3-none-any.whl.metadata\n",
      "  Downloading praatio-6.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: typing-extensions in ./anaconda3/lib/python3.11/site-packages (from praatio) (4.11.0)\n",
      "Downloading praatio-6.2.0-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.0/80.0 kB\u001b[0m \u001b[31m574.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: praatio\n",
      "Successfully installed praatio-6.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install praatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1b124d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import parselmouth\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import textgrid\n",
    "import glob\n",
    "from parselmouth.praat import call\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textgrid import TextGrid\n",
    "import parselmouth\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from praatio import textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8807ae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"Downloads/acoustic_framework-main-2/\"\n",
    "output_dir = \"Downloads/TRIAL_ACOUSTIC/\"  # Output directory for saving files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dab8bb",
   "metadata": {},
   "source": [
    "# ---------------- CPP Extraction Function ---------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903778c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Final data saved to Downloads/TRIAL_ACOUSTIC/Cepstrum_Data_For_Spreadsheets_3.csv\n"
     ]
    }
   ],
   "source": [
    "def calculate_cpp(snd, onset, offset):\n",
    "    sound_part = snd.extract_part(from_time=onset, to_time=offset, \n",
    "                                  window_shape=parselmouth.WindowShape.HAMMING, \n",
    "                                  relative_width=1.988)\n",
    "    parselmouth.praat.call(sound_part, \"To Formant (burg)\", 0, 5, 5000, 0.0025, 50)\n",
    "    \n",
    "    power_cepstrogram = parselmouth.praat.call(sound_part, \"To PowerCepstrogram\", 60, 0.002, 5000, 50)\n",
    "    parselmouth.praat.call(power_cepstrogram, \"Smooth\", 0.02, 0.0005)\n",
    "    \n",
    "    cpps = parselmouth.praat.call(power_cepstrogram, \"Get CPPS\", \"yes\", 0.02, 0.0005, \n",
    "                                  60, 330, 0.05, \"Parabolic\", 0.001, 0, \n",
    "                                  \"Exponential decay\", \"Robust\")\n",
    "    return cpps\n",
    "\n",
    "def process_file(textgrid_path, snd, participant_name):\n",
    "    output = []\n",
    "    tg = parselmouth.praat.call(\"Read from file\", textgrid_path)\n",
    "    num_intervals = parselmouth.praat.call(tg, \"Get number of intervals\", 3)\n",
    "\n",
    "    for i in range(1, num_intervals + 1):\n",
    "        label = parselmouth.praat.call(tg, \"Get label of interval\", 3, i)\n",
    "        if label.startswith(\"puhtuhkuh\"):\n",
    "            onset = parselmouth.praat.call(tg, \"Get start point\", 3, i)\n",
    "            offset = parselmouth.praat.call(tg, \"Get end point\", 3, i)\n",
    "            cpps = calculate_cpp(snd, onset, offset)\n",
    "\n",
    "            task, rep = label[:9], label[9] if len(label) > 9 else \"N/A\"\n",
    "            output.append([participant_name, task, rep, cpps])\n",
    "    \n",
    "    return output\n",
    "\n",
    "def main():\n",
    "    output_rows = [[\"Participant\", \"Task\", \"Rep\", \"CPPS\"]]\n",
    "    \n",
    "    for filename in os.listdir(project_dir):\n",
    "        if not filename.endswith(\".TextGrid\"):\n",
    "            continue\n",
    "\n",
    "        textgrid_path = os.path.join(project_dir, filename)\n",
    "        wav_path = textgrid_path.replace(\".TextGrid\", \".wav\")\n",
    "        participant_name = filename.replace(\".TextGrid\", \"\")\n",
    "\n",
    "        if not os.path.exists(wav_path):\n",
    "            print(f\"Missing wav file for {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            snd = parselmouth.Sound(wav_path)\n",
    "            output_rows.extend(process_file(textgrid_path, snd, participant_name))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "    # Save the initial CSV to the output directory\n",
    "    intermediate_csv = os.path.join(output_dir, \"Cepstrum_Data_For_R.csv\")\n",
    "    with open(intermediate_csv, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerows(output_rows)\n",
    "\n",
    "    # Expand rows and save the final output to the output directory\n",
    "    cepstrum_data = pd.read_csv(intermediate_csv)\n",
    "    cepstrum_data_expanded = pd.DataFrame(np.repeat(cepstrum_data.values, 3, axis=0), \n",
    "                                          columns=cepstrum_data.columns)\n",
    "    \n",
    "    final_csv = os.path.join(output_dir, \"Cepstrum_Data_For_Spreadsheets_3.csv\")\n",
    "    cepstrum_data_expanded.astype(str).to_csv(final_csv, index=False)\n",
    "\n",
    "    print(\"Processing complete. Final data saved to\", final_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b929c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Participant   Task      Time           F1           F2  Duration\n",
      "0    Normal_Hannah_DDK  p1VOT  0.759834  1118.323577  2444.126956  0.078827\n",
      "1    Normal_Hannah_DDK  p1VOT  0.762334  1222.414044  2133.776636  0.078827\n",
      "2    Normal_Hannah_DDK  p1VOT  0.764834   571.974237  1405.971421  0.078827\n",
      "3    Normal_Hannah_DDK  p1VOT  0.767334   570.690694  1341.239056  0.078827\n",
      "4    Normal_Hannah_DDK  p1VOT  0.769834  1198.765047  2412.026580  0.078827\n",
      "..                 ...    ...       ...          ...          ...       ...\n",
      "713  Normal_Hannah_DDK   kuh3  3.176164   853.482162   894.750452  0.148020\n",
      "714  Normal_Hannah_DDK   kuh3  3.178664   763.891360  1459.318191  0.148020\n",
      "715  Normal_Hannah_DDK   kuh3  3.181164  1182.663352  1755.111966  0.148020\n",
      "716  Normal_Hannah_DDK   kuh3  3.183664   992.845753  1442.636294  0.148020\n",
      "717  Normal_Hannah_DDK   kuh3  3.186164   751.909660  1031.103111  0.148020\n",
      "\n",
      "[718 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------------- FORMANT Extraction Function PRAAT ---------------- #\n",
    "\n",
    "# Make a list of all TextGrid files in the folder\n",
    "textgrid_files = glob.glob(os.path.join(project_dir, '*.TextGrid'))\n",
    "\n",
    "# Collect results in a list\n",
    "results = []\n",
    "\n",
    "# Loop through the list of TextGrid files\n",
    "for textgrid_file in textgrid_files:\n",
    "    filename = os.path.basename(textgrid_file).replace('.TextGrid', '')\n",
    "\n",
    "    # Read the TextGrid and corresponding .wav file\n",
    "    textgrid_path = os.path.join(project_dir, filename + \".TextGrid\")\n",
    "    sound_path = os.path.join(project_dir, filename + \".wav\")\n",
    "\n",
    "    if not os.path.exists(sound_path):\n",
    "        print(f\"Sound file for {filename} not found. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        tg = parselmouth.Data.read(textgrid_path)  # Read TextGrid\n",
    "        sound = parselmouth.Sound(sound_path)      # Read corresponding sound file\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Select the first tier (vowel tier assumption)\n",
    "    try:\n",
    "        number_of_intervals = call(tg, \"Get number of intervals\", 1)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get intervals for {filename}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Create the Formant object\n",
    "    formant = call(sound, \"To Formant (burg)...\", 0, 5, 5000, 0.0025, 50)\n",
    "\n",
    "    # Loop through each interval in the first tier\n",
    "    for interval_index in range(1, number_of_intervals + 1):\n",
    "        phoneme = call(tg, \"Get label of interval\", 1, interval_index).strip()\n",
    "\n",
    "        if phoneme != \"\":\n",
    "            start_time = call(tg, \"Get start point\", 1, interval_index)\n",
    "            end_time = call(tg, \"Get end point\", 1, interval_index)\n",
    "            duration = end_time - start_time\n",
    "\n",
    "            # Determine number of frames based on duration and frame interval (0.0025s)\n",
    "            frame_count = int(duration / 0.0025)\n",
    "\n",
    "            # Loop through each frame in the interval\n",
    "            for frame in range(frame_count):\n",
    "                frame_time = start_time + (frame * 0.0025)\n",
    "\n",
    "                # Get formant values at the specified time\n",
    "                f1 = call(formant, \"Get value at time\", 1, frame_time, \"Hertz\", \"Linear\")\n",
    "                f2 = call(formant, \"Get value at time\", 2, frame_time, \"Hertz\", \"Linear\")\n",
    "\n",
    "                # Store results in the list\n",
    "                results.append([filename, phoneme, frame_time, f1, f2, duration])\n",
    "\n",
    "# Print results as a DataFrame\n",
    "df_results = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"Participant\", \"Task\", \"Time\", \"F1\", \"F2\", \"Duration\"]\n",
    ")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd770fd",
   "metadata": {},
   "source": [
    "# ---------------- Formant Extraction Function ---------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8063a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Formant Extraction Function MATLAB ---------------- #\n",
    "\n",
    "def process_formant_data(df_results):\n",
    "    pd.set_option('display.float_format', lambda x: f'{x:.12g}')\n",
    "\n",
    "    columns = [\n",
    "        'Participant', 'Task', 'Vow', 'OnsetFreq_1', 'OnsetFreq_2', 'OffsetFreq_1',\n",
    "        'OffsetFreq_2', 'Range_1', 'Range_2', 'Slope_1', 'Slope_2',\n",
    "        'F1xF2Xcorr', 'F1xF2Corr', 'F1xF2Cov', 'Ratio_1', 'Ratio_2',\n",
    "        'F1Vel', 'F1Accel', 'F1Jerk', 'F2Vel', 'F2Accel', 'F2Jerk'\n",
    "    ]\n",
    "    results_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "    unique_participants = df_results['Participant'].unique()\n",
    "\n",
    "    for participant in unique_participants:\n",
    "        participant_data = df_results[df_results['Participant'] == participant]\n",
    "        unique_tasks = participant_data['Task'].unique()\n",
    "\n",
    "        for task in unique_tasks:\n",
    "            task_data = participant_data[participant_data['Task'] == task]\n",
    "            task_numbers = task_data.iloc[:, 2:6].to_numpy()\n",
    "\n",
    "            if 'VOT' in task:\n",
    "                duration = task_numbers[0, 3]\n",
    "                this_row = pd.DataFrame([[\n",
    "                    participant, task, duration, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "                ]], columns=columns)\n",
    "                results_table = pd.concat([results_table, this_row], ignore_index=True)\n",
    "                continue\n",
    "\n",
    "            # Extract position and time for F1 and F2\n",
    "            F1_position, F2_position = task_numbers[:, 1], task_numbers[:, 2]\n",
    "            F1_time, F2_time = task_numbers[:, 0], task_numbers[:, 0]\n",
    "\n",
    "            # Calculate velocity, acceleration, and jerk for F1\n",
    "            F1_vel = np.diff(F1_position) / np.diff(F1_time)\n",
    "            F1_accel = np.diff(F1_vel) / np.diff(F1_time[:-1])\n",
    "            F1_jerk = np.diff(F1_accel) / np.diff(F1_time[:-2])\n",
    "\n",
    "            # Apply padding after calculations\n",
    "            F1_vel = np.pad(F1_vel, (0, 1), constant_values=np.nan)\n",
    "            F1_accel = np.pad(F1_accel, (0, 2), constant_values=np.nan)\n",
    "            F1_jerk = np.pad(F1_jerk, (0, 3), constant_values=np.nan)\n",
    "\n",
    "            # Calculate velocity, acceleration, and jerk for F2\n",
    "            F2_vel = np.diff(F2_position) / np.diff(F2_time)\n",
    "            F2_accel = np.diff(F2_vel) / np.diff(F2_time[:-1])\n",
    "            F2_jerk = np.diff(F2_accel) / np.diff(F2_time[:-2])\n",
    "\n",
    "            F2_vel = np.pad(F2_vel, (0, 1), constant_values=np.nan)\n",
    "            F2_accel = np.pad(F2_accel, (0, 2), constant_values=np.nan)\n",
    "            F2_jerk = np.pad(F2_jerk, (0, 3), constant_values=np.nan)\n",
    "\n",
    "            # Calculate slopes and ranges\n",
    "            mid_point = len(task_numbers) // 2\n",
    "            time_mat = task_numbers[:mid_point, 0]\n",
    "            data_half_mat = task_numbers[:mid_point, 1:3]\n",
    "\n",
    "            dur = time_mat[-1] - time_mat[0]\n",
    "            onset_freq = data_half_mat[0, :]\n",
    "            offset_freq = data_half_mat[-1, :]\n",
    "            range_mat = offset_freq - onset_freq\n",
    "            slope_mat = (offset_freq - onset_freq) / dur\n",
    "\n",
    "            # Calculate correlation and covariance\n",
    "            F1xF2_corr = np.corrcoef(task_numbers[:, 1], task_numbers[:, 2])[0, 1]\n",
    "            F1xF2_cov = np.cov(task_numbers[:, 1], task_numbers[:, 2])[0, 1]\n",
    "            F1xF2_xcorr = np.correlate(task_numbers[:, 1], task_numbers[:, 2], mode='full') / len(task_numbers[:, 1])\n",
    "            F1xF2_xcorr = F1xF2_xcorr[len(task_numbers[:, 1]) - 1]\n",
    "\n",
    "            ratio = onset_freq / offset_freq\n",
    "\n",
    "            # Store results\n",
    "            this_row = pd.DataFrame([[\n",
    "                participant, task, dur, onset_freq[0], onset_freq[1],\n",
    "                offset_freq[0], offset_freq[1], range_mat[0], range_mat[1],\n",
    "                slope_mat[0], slope_mat[1], F1xF2_xcorr, F1xF2_corr,\n",
    "                F1xF2_cov, ratio[0], ratio[1], np.nanmean(F1_vel),\n",
    "                np.nanmean(F1_accel), np.nanmean(F1_jerk),\n",
    "                np.nanmean(F2_vel), np.nanmean(F2_accel), np.nanmean(F2_jerk)\n",
    "            ]], columns=columns)\n",
    "\n",
    "            results_table = pd.concat([results_table, this_row], ignore_index=True)\n",
    "\n",
    "    return results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564f6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Participant   Task             Vow   OnsetFreq_1   OnsetFreq_2  \\\n",
      "0   Normal_Hannah_DDK  p1VOT 0.0788273634806             0             0   \n",
      "1   Normal_Hannah_DDK   puh1          0.0525 676.470107905 1027.22535907   \n",
      "2   Normal_Hannah_DDK  t1VOT 0.0543032948422             0             0   \n",
      "3   Normal_Hannah_DDK   tuh1          0.0825 736.101404342 2016.97058248   \n",
      "4   Normal_Hannah_DDK  k1VOT 0.0586825928134             0             0   \n",
      "5   Normal_Hannah_DDK   kuh1           0.075 787.875712622 2159.11842067   \n",
      "6   Normal_Hannah_DDK  p2VOT 0.0411654009288             0             0   \n",
      "7   Normal_Hannah_DDK   puh2          0.0625 921.313006474  1875.6304276   \n",
      "8   Normal_Hannah_DDK  t2VOT 0.0516757160595             0             0   \n",
      "9   Normal_Hannah_DDK   tuh2          0.0875 1249.90610769 2372.41735058   \n",
      "10  Normal_Hannah_DDK  k2VOT  0.053427435248             0             0   \n",
      "11  Normal_Hannah_DDK   kuh2          0.0675 901.451603641 2226.42743335   \n",
      "12  Normal_Hannah_DDK  p3VOT 0.0423075875799             0             0   \n",
      "13  Normal_Hannah_DDK   puh3           0.065  903.03824012  1980.5641368   \n",
      "14  Normal_Hannah_DDK  t3VOT 0.0621860311903             0             0   \n",
      "15  Normal_Hannah_DDK   tuh3            0.06 326.450670244 2056.45150068   \n",
      "16  Normal_Hannah_DDK  k3VOT 0.0630618907845             0             0   \n",
      "17  Normal_Hannah_DDK   kuh3            0.07 685.651552397 1479.63171508   \n",
      "\n",
      "    OffsetFreq_1  OffsetFreq_2        Range_1        Range_2        Slope_1  \\\n",
      "0              0             0              0              0              0   \n",
      "1  777.172800832 1708.84310552  100.702692927  681.617746448  1918.14653194   \n",
      "2              0             0              0              0              0   \n",
      "3  667.490105803 1022.54454591 -68.6112985389 -994.426036574 -831.652103501   \n",
      "4              0             0              0              0              0   \n",
      "5   726.64065386 1248.34879117 -61.2350587623 -910.769629503 -816.467450164   \n",
      "6              0             0              0              0              0   \n",
      "7  830.633644001 1747.92677467 -90.6793624735 -127.703652938 -1450.86979958   \n",
      "8              0             0              0              0              0   \n",
      "9  699.926462642 1905.34448657 -549.979645045 -467.072864009 -6285.48165765   \n",
      "10             0             0              0              0              0   \n",
      "11 802.208376277 1934.70255325 -99.2432273636 -291.724880093 -1470.27003502   \n",
      "12             0             0              0              0              0   \n",
      "13  791.93259837 1454.86783689  -111.10564175 -525.696299907 -1709.31756538   \n",
      "14             0             0              0              0              0   \n",
      "15 793.862099822 1949.34188434  467.411429578 -107.109616342  7790.19049297   \n",
      "16             0             0              0              0              0   \n",
      "17 868.398347256 1745.94743624  182.746794859  266.315721161  2610.66849799   \n",
      "\n",
      "    ...       F1xF2Corr      F1xF2Cov        Ratio_1        Ratio_2  \\\n",
      "0   ...               0             0              0              0   \n",
      "1   ...  0.231918938604 19513.7656653 0.870424321568 0.601123272085   \n",
      "2   ...               0             0              0              0   \n",
      "3   ... 0.0929732515433 5157.26967124  1.10278998586  1.97250143336   \n",
      "4   ...               0             0              0              0   \n",
      "5   ...  0.334616290377 22399.4800908  1.08427144619  1.72957945403   \n",
      "6   ...               0             0              0              0   \n",
      "7   ...  0.464463889703 26580.9763865  1.10916890151  1.07306007024   \n",
      "8   ...               0             0              0              0   \n",
      "9   ...  0.171253774775 8492.58870159  1.78576775476  1.24513827673   \n",
      "10  ...               0             0              0              0   \n",
      "11  ...  0.590506308728 44446.2032496  1.12371252944  1.15078539055   \n",
      "12  ...               0             0              0              0   \n",
      "13  ...  0.503206557912 28020.5313448  1.14029684089  1.36133612042   \n",
      "14  ...               0             0              0              0   \n",
      "15  ...  0.249779408119 16516.2075922 0.411218359356  1.05494655258   \n",
      "16  ...               0             0              0              0   \n",
      "17  ...  0.423386228982  17364.877987 0.789558794721 0.847466358017   \n",
      "\n",
      "            F1Vel        F1Accel         F1Jerk          F2Vel        F2Accel  \\\n",
      "0               0              0              0              0              0   \n",
      "1   660.232886851 -1177842.08459  1983995273.94  8990.77141577 -897048.068937   \n",
      "2               0              0              0              0              0   \n",
      "3   496.340735737  2025875.07003  358292574.614 -1488.79600317  270276.448859   \n",
      "4               0              0              0              0              0   \n",
      "5   656.808158285  2816200.02336 -319661518.994 -4254.58239271  267312.805601   \n",
      "6               0              0              0              0              0   \n",
      "7  -2703.62362994  -691200.47961 -948859934.126 -2642.48000278 -581639.952831   \n",
      "8               0              0              0              0              0   \n",
      "9  -4932.67679263  1612039.08938 -1098700790.69 -2904.26425354  588353.984292   \n",
      "10              0              0              0              0              0   \n",
      "11 -2299.95995838  1262408.88106  90979761.9692 -5667.51434957   5911422.4301   \n",
      "12              0              0              0              0              0   \n",
      "13 -837.094533617  888619.071229 -297902585.096  2187.58444337  889756.308949   \n",
      "14              0              0              0              0              0   \n",
      "15 -293.033438833 -732021.715974 -114494085.889 -1628.09620897 -135428.920927   \n",
      "16              0              0              0              0              0   \n",
      "17  456.952466831 -416742.407095 -624109043.068 -3093.30071434  -2033999.3893   \n",
      "\n",
      "           F2Jerk  \n",
      "0               0  \n",
      "1   2081758424.57  \n",
      "2               0  \n",
      "3  -45207910.0231  \n",
      "4               0  \n",
      "5  -1625514371.38  \n",
      "6               0  \n",
      "7  -1236944079.83  \n",
      "8               0  \n",
      "9  -414207264.193  \n",
      "10              0  \n",
      "11 -1354294126.36  \n",
      "12              0  \n",
      "13 -729356332.405  \n",
      "14              0  \n",
      "15  687479317.775  \n",
      "16              0  \n",
      "17  214135365.975  \n",
      "\n",
      "[18 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "processed_results = process_formant_data(df_results)\n",
    "print(processed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6605ac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data rows: 18\n",
      "Number of formant rows: 9\n",
      "Number of VOT rows: 9\n",
      "         Participant Rep  VOT Task    Vow   OnsetFreq_1   OnsetFreq_2  \\\n",
      "1  Normal_Hannah_DDK   1    1  puh 0.0525 676.470107905 1027.22535907   \n",
      "3  Normal_Hannah_DDK   1    1  tuh 0.0825 736.101404342 2016.97058248   \n",
      "5  Normal_Hannah_DDK   1    1  kuh  0.075 787.875712622 2159.11842067   \n",
      "7  Normal_Hannah_DDK   2    1  puh 0.0625 921.313006474  1875.6304276   \n",
      "9  Normal_Hannah_DDK   2    1  tuh 0.0875 1249.90610769 2372.41735058   \n",
      "\n",
      "   OffsetFreq_1  OffsetFreq_2        Range_1  ...       F1xF2Corr  \\\n",
      "1 777.172800832 1708.84310552  100.702692927  ...  0.231918938604   \n",
      "3 667.490105803 1022.54454591 -68.6112985389  ... 0.0929732515433   \n",
      "5  726.64065386 1248.34879117 -61.2350587623  ...  0.334616290377   \n",
      "7 830.633644001 1747.92677467 -90.6793624735  ...  0.464463889703   \n",
      "9 699.926462642 1905.34448657 -549.979645045  ...  0.171253774775   \n",
      "\n",
      "       F1xF2Cov        Ratio_1        Ratio_2          F1Vel        F1Accel  \\\n",
      "1 19513.7656653 0.870424321568 0.601123272085  660.232886851 -1177842.08459   \n",
      "3 5157.26967124  1.10278998586  1.97250143336  496.340735737  2025875.07003   \n",
      "5 22399.4800908  1.08427144619  1.72957945403  656.808158285  2816200.02336   \n",
      "7 26580.9763865  1.10916890151  1.07306007024 -2703.62362994  -691200.47961   \n",
      "9 8492.58870159  1.78576775476  1.24513827673 -4932.67679263  1612039.08938   \n",
      "\n",
      "          F1Jerk          F2Vel        F2Accel         F2Jerk  \n",
      "1  1983995273.94  8990.77141577 -897048.068937  2081758424.57  \n",
      "3  358292574.614 -1488.79600317  270276.448859 -45207910.0231  \n",
      "5 -319661518.994 -4254.58239271  267312.805601 -1625514371.38  \n",
      "7 -948859934.126 -2642.48000278 -581639.952831 -1236944079.83  \n",
      "9 -1098700790.69 -2904.26425354  588353.984292 -414207264.193  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Formant Extraction Function Python ---------------- #\n",
    "\n",
    "def vot_name_to_formant_name(vot_name):\n",
    "    \"\"\"Convert VOT task name to corresponding formant task name.\"\"\"\n",
    "    return vot_name[0] + \"uh\" + vot_name[1]\n",
    "\n",
    "# Process the results_table DataFrame\n",
    "def process_vot_and_formant_data(results_table):\n",
    "    # Separate VOT and formant rows\n",
    "    vot_rows = processed_results[processed_results['Task'].str.contains(\"VOT\")]\n",
    "    formant_rows = processed_results[~processed_results['Task'].str.contains(\"VOT\")]\n",
    "\n",
    "    print(f\"Total data rows: {len(processed_results)}\")\n",
    "    print(f\"Number of formant rows: {len(formant_rows)}\")\n",
    "    print(f\"Number of VOT rows: {len(vot_rows)}\")\n",
    "\n",
    "    updated_rows = []\n",
    "\n",
    "    for _, formant_row in formant_rows.iterrows():\n",
    "        matching_vot_row = vot_rows[\n",
    "            (vot_rows['Participant'] == formant_row['Participant']) & \n",
    "            (vot_rows['Task'].apply(vot_name_to_formant_name) == formant_row['Task'])\n",
    "        ]\n",
    "\n",
    "        # Assign placeholder VOT value if no match is found\n",
    "        if not matching_vot_row.empty:\n",
    "            formant_row['VOT'] = 1  # Placeholder value for VOT\n",
    "        else:\n",
    "            formant_row['VOT'] = np.nan\n",
    "        \n",
    "        # Extract repetition number from task name (e.g., puh2 -> 2)\n",
    "        formant_row['Rep'] = formant_row['Task'][3] if len(formant_row['Task']) > 3 else \"1\"\n",
    "        formant_row['Task'] = formant_row['Task'][:3]  # Reduce to puh, tuh, kuh\n",
    "        updated_rows.append(formant_row)\n",
    "\n",
    "    updated_results = pd.DataFrame(updated_rows)\n",
    "    updated_results = updated_results[['Participant', 'Rep', 'VOT'] + \n",
    "                                      [col for col in updated_results.columns if col not in ['Participant', 'Rep', 'VOT']]]\n",
    "\n",
    "    print(updated_results.head())\n",
    "    return updated_results\n",
    "\n",
    "# Process and save the updated DataFrame\n",
    "updated_results_df = process_vot_and_formant_data(processed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23127def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Task  VOT    Vow   Syll    VOTVowProp    VOTSyllProp     VowSyllProp  \\\n",
      "0  puh    1 0.0525 1.0525 19.0476190476 0.950118764846 0.0498812351544   \n",
      "1  tuh    1 0.0825 1.0825 12.1212121212 0.923787528868 0.0762124711316   \n",
      "2  kuh    1  0.075  1.075 13.3333333333  0.93023255814 0.0697674418605   \n",
      "3  puh    1 0.0625 1.0625            16 0.941176470588 0.0588235294118   \n",
      "4  tuh    1 0.0875 1.0875 11.4285714286 0.919540229885 0.0804597701149   \n",
      "5  kuh    1 0.0675 1.0675 14.8148148148 0.936768149883 0.0632318501171   \n",
      "6  puh    1  0.065  1.065 15.3846153846  0.93896713615 0.0610328638498   \n",
      "7  tuh    1   0.06   1.06 16.6666666667 0.943396226415 0.0566037735849   \n",
      "8  kuh    1   0.07   1.07 14.2857142857 0.934579439252 0.0654205607477   \n",
      "\n",
      "    F1OnsetFreq   F2OnsetFreq      ConSpace  ...  RepVar_F1xF2Corr  \\\n",
      "0 676.470107905 1027.22535907 350.755251163  ...     36.6946249773   \n",
      "1 736.101404342 2016.97058248 1280.86917814  ...      45.759997325   \n",
      "2 787.875712622 2159.11842067 1371.24270805  ...      28.904989475   \n",
      "3 921.313006474  1875.6304276 954.317421129  ...     36.6946249773   \n",
      "4 1249.90610769 2372.41735058 1122.51124289  ...      45.759997325   \n",
      "5 901.451603641 2226.42743335 1324.97582971  ...      28.904989475   \n",
      "6  903.03824012  1980.5641368 1077.52589668  ...     36.6946249773   \n",
      "7 326.450670244 2056.45150068 1730.00083043  ...      45.759997325   \n",
      "8 685.651552397 1479.63171508 793.980162678  ...      28.904989475   \n",
      "\n",
      "   RepVar_F1xF2Cov  RepVar_F1Ratio  RepVar_F2Ratio   RepVar_F1Vel  \\\n",
      "0    18.4296956459   14.1973966519     37.92953917 -175.522685132   \n",
      "1    58.0635573838   62.4841644724   34.0034500126 -186.065848393   \n",
      "2    51.3132414576   18.2755762604    36.066672156 -417.911657211   \n",
      "3    18.4296956459   14.1973966519     37.92953917 -175.522685132   \n",
      "4    58.0635573838   62.4841644724   34.0034500126 -186.065848393   \n",
      "5    51.3132414576   18.2755762604    36.066672156 -417.911657211   \n",
      "6    18.4296956459   14.1973966519     37.92953917 -175.522685132   \n",
      "7    58.0635573838   62.4841644724   34.0034500126 -186.065848393   \n",
      "8    51.3132414576   18.2755762604    36.066672156 -417.911657211   \n",
      "\n",
      "   RepVar_F1Accel  RepVar_F1Jerk   RepVar_F2Vel  RepVar_F2Accel  RepVar_F2Jerk  \n",
      "0  -330.575939957  626.730360288  205.407663144  -485.807256295  4644.89204335  \n",
      "1   153.543788111 -260.838804984  -38.869139382   150.486878983  737.633364992  \n",
      "2   132.463287072 -126.240637858 -29.7145422561   295.910040181 -107.727476251  \n",
      "3  -330.575939957  626.730360288  205.407663144  -485.807256295  4644.89204335  \n",
      "4   153.543788111 -260.838804984  -38.869139382   150.486878983  737.633364992  \n",
      "5   132.463287072 -126.240637858 -29.7145422561   295.910040181 -107.727476251  \n",
      "6  -330.575939957  626.730360288  205.407663144  -485.807256295  4644.89204335  \n",
      "7   153.543788111 -260.838804984  -38.869139382   150.486878983  737.633364992  \n",
      "8   132.463287072 -126.240637858 -29.7145422561   295.910040181 -107.727476251  \n",
      "\n",
      "[9 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# Assuming updated_results_df is the input DataFrame\n",
    "formantData = updated_results_df\n",
    "\n",
    "formantData['Task'] = formantData['Task'].str.replace('_', '', regex=False)  # Remove underscores\n",
    "\n",
    "rename_map = {\n",
    "    \"OnsetFreq_1\":  \"F1OnsetFreq\",\n",
    "    \"OnsetFreq_2\":  \"F2OnsetFreq\",\n",
    "    \"OffsetFreq_1\": \"F1OffsetFreq\",\n",
    "    \"OffsetFreq_2\": \"F2OffsetFreq\",\n",
    "    \"Range_1\":      \"F1Range\",\n",
    "    \"Range_2\":      \"F2Range\",\n",
    "    \"Slope_1\":      \"F1Slope\",\n",
    "    \"Slope_2\":      \"F2Slope\",\n",
    "    \"Ratio_1\":      \"F1Ratio\",\n",
    "    \"Ratio_2\":      \"F2Ratio\"\n",
    "}\n",
    "formantData.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "\n",
    "# 3) Convert columns to numeric\n",
    "numeric_cols = [\n",
    "    \"F1OnsetFreq\", \"F2OnsetFreq\", \"F1OffsetFreq\", \"F2OffsetFreq\",\n",
    "    \"F1Range\", \"F2Range\", \"F1Slope\", \"F2Slope\", \"F1Ratio\", \"F2Ratio\"\n",
    "]\n",
    "formantData[numeric_cols] = formantData[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# 4) Create 'syllable' with derived metrics\n",
    "formantData[\"Syll\"] = formantData[\"VOT\"] + formantData[\"Vow\"]\n",
    "formantData[\"ConSpace\"] = formantData[\"F2OnsetFreq\"] - formantData[\"F1OnsetFreq\"]\n",
    "formantData[\"VowSpace\"] = formantData[\"F2OffsetFreq\"] - formantData[\"F1OffsetFreq\"]\n",
    "formantData[\"F1Range\"] = formantData[\"F1Range\"].abs()\n",
    "formantData[\"F2Range\"] = formantData[\"F2Range\"].abs()\n",
    "\n",
    "syllable_cols = [\n",
    "    \"Participant\", \"Rep\", \"Task\",\n",
    "    \"VOT\", \"Vow\", \"Syll\",\n",
    "    \"F1OnsetFreq\", \"F2OnsetFreq\", \"ConSpace\",\n",
    "    \"F1OffsetFreq\", \"F2OffsetFreq\", \"VowSpace\",\n",
    "    \"F1Range\", \"F2Range\",\n",
    "    \"F1Slope\", \"F2Slope\",\n",
    "    \"F1xF2Xcorr\", \"F1xF2Corr\", \"F1xF2Cov\",\n",
    "    \"F1Ratio\", \"F2Ratio\",\n",
    "    \"F1Vel\", \"F1Accel\", \"F1Jerk\",\n",
    "    \"F2Vel\", \"F2Accel\", \"F2Jerk\"\n",
    "]\n",
    "syllable = formantData[syllable_cols].copy()\n",
    "\n",
    "# 5) Calculate proportions\n",
    "syllable[\"VOTVowProp\"] = syllable[\"VOT\"] / syllable[\"Vow\"]\n",
    "syllable[\"VOTSyllProp\"] = syllable[\"VOT\"] / syllable[\"Syll\"]\n",
    "syllable[\"VowSyllProp\"] = syllable[\"Vow\"] / syllable[\"Syll\"]\n",
    "\n",
    "proportions_cols = syllable_cols + [\"VOTVowProp\", \"VOTSyllProp\", \"VowSyllProp\"]\n",
    "proportions = syllable[proportions_cols].copy()\n",
    "\n",
    "# 6) Calculate precision\n",
    "precision = proportions.copy()\n",
    "var_cols = [\n",
    "    \"VOT\", \"Vow\", \"Syll\",\n",
    "    \"VOTVowProp\", \"VOTSyllProp\", \"VowSyllProp\",\n",
    "    \"F1OnsetFreq\", \"F2OnsetFreq\", \"ConSpace\",\n",
    "    \"F1OffsetFreq\", \"F2OffsetFreq\", \"VowSpace\",\n",
    "    \"F1Range\", \"F2Range\",\n",
    "    \"F1Slope\", \"F2Slope\",\n",
    "    \"F1xF2Xcorr\", \"F1xF2Corr\", \"F1xF2Cov\",\n",
    "    \"F1Ratio\", \"F2Ratio\",\n",
    "    \"F1Vel\", \"F1Accel\", \"F1Jerk\",\n",
    "    \"F2Vel\", \"F2Accel\", \"F2Jerk\"\n",
    "]\n",
    "group_cols = [\"Participant\", \"Rep\"]\n",
    "\n",
    "for c in var_cols:\n",
    "    precision[f\"PhonVar_{c}\"] = precision.groupby(group_cols)[c].transform(\"std\")\n",
    "\n",
    "# 7) Calculate precision consistency\n",
    "precision_consistency = precision.copy()\n",
    "group_cols_2 = [\"Participant\", \"Task\"]\n",
    "\n",
    "for c in var_cols:\n",
    "    std_col = precision_consistency.groupby(group_cols_2)[c].transform(\"std\")\n",
    "    mean_col = precision_consistency.groupby(group_cols_2)[c].transform(\"mean\")\n",
    "    precision_consistency[f\"RepVar_{c}\"] = (std_col / mean_col) * 100\n",
    "\n",
    "# 8) Create 'data' for export\n",
    "final_cols = [\n",
    "    \"Task\", \"VOT\", \"Vow\", \"Syll\",\n",
    "    \"VOTVowProp\", \"VOTSyllProp\", \"VowSyllProp\",\n",
    "    \"F1OnsetFreq\", \"F2OnsetFreq\", \"ConSpace\",\n",
    "    \"F1OffsetFreq\", \"F2OffsetFreq\", \"VowSpace\",\n",
    "    \"F1Range\", \"F2Range\",\n",
    "    \"F1Slope\", \"F2Slope\",\n",
    "    \"F1xF2Xcorr\", \"F1xF2Corr\", \"F1xF2Cov\",\n",
    "    \"F1Ratio\", \"F2Ratio\",\n",
    "    \"F1Vel\", \"F1Accel\", \"F1Jerk\",\n",
    "    \"F2Vel\", \"F2Accel\", \"F2Jerk\",\n",
    "]\n",
    "\n",
    "phonvar_cols = [f\"PhonVar_{c}\" for c in var_cols]\n",
    "repvar_cols = [f\"RepVar_{c}\" for c in var_cols]\n",
    "final_cols.extend(phonvar_cols)\n",
    "final_cols.extend(repvar_cols)\n",
    "\n",
    "data = (\n",
    "    precision_consistency\n",
    "    .groupby([\"Participant\", \"Rep\"], as_index=False)\n",
    "    [final_cols]\n",
    "    .apply(lambda g: g)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 9) Write to CSV\n",
    "#out_path = \"/Users/DELL/Downloads/acoustic_framework-main-2/Formant_Data_For_Spreadsheets.csv\"\n",
    "#data.to_csv(out_path, index=False)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68c8f2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Task  VOT    Vow   Syll    VOTVowProp    VOTSyllProp     VowSyllProp  \\\n",
      "0  puh1    1 0.0525 1.0525 19.0476190476 0.950118764846 0.0498812351544   \n",
      "1  tuh1    1 0.0825 1.0825 12.1212121212 0.923787528868 0.0762124711316   \n",
      "2  kuh1    1  0.075  1.075 13.3333333333  0.93023255814 0.0697674418605   \n",
      "3  puh2    1 0.0625 1.0625            16 0.941176470588 0.0588235294118   \n",
      "4  tuh2    1 0.0875 1.0875 11.4285714286 0.919540229885 0.0804597701149   \n",
      "\n",
      "    F1OnsetFreq   F2OnsetFreq      ConSpace  ...  RepVar_F1xF2Corr  \\\n",
      "0 676.470107905 1027.22535907 350.755251163  ...     36.6946249773   \n",
      "1 736.101404342 2016.97058248 1280.86917814  ...      45.759997325   \n",
      "2 787.875712622 2159.11842067 1371.24270805  ...      28.904989475   \n",
      "3 921.313006474  1875.6304276 954.317421129  ...     36.6946249773   \n",
      "4 1249.90610769 2372.41735058 1122.51124289  ...      45.759997325   \n",
      "\n",
      "   RepVar_F1xF2Cov  RepVar_F1Ratio  RepVar_F2Ratio   RepVar_F1Vel  \\\n",
      "0    18.4296956459   14.1973966519     37.92953917 -175.522685132   \n",
      "1    58.0635573838   62.4841644724   34.0034500126 -186.065848393   \n",
      "2    51.3132414576   18.2755762604    36.066672156 -417.911657211   \n",
      "3    18.4296956459   14.1973966519     37.92953917 -175.522685132   \n",
      "4    58.0635573838   62.4841644724   34.0034500126 -186.065848393   \n",
      "\n",
      "   RepVar_F1Accel  RepVar_F1Jerk   RepVar_F2Vel  RepVar_F2Accel  RepVar_F2Jerk  \n",
      "0  -330.575939957  626.730360288  205.407663144  -485.807256295  4644.89204335  \n",
      "1   153.543788111 -260.838804984  -38.869139382   150.486878983  737.633364992  \n",
      "2   132.463287072 -126.240637858 -29.7145422561   295.910040181 -107.727476251  \n",
      "3  -330.575939957  626.730360288  205.407663144  -485.807256295  4644.89204335  \n",
      "4   153.543788111 -260.838804984  -38.869139382   150.486878983  737.633364992  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "# Append repetition numbers directly to the Task column\n",
    "data['Task'] = data['Task'] + (data.groupby('Task').cumcount() + 1).astype(str)\n",
    "\n",
    "# Verify the updated DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8199d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>VOT</th>\n",
       "      <th>Vow</th>\n",
       "      <th>Syll</th>\n",
       "      <th>VOTVowProp</th>\n",
       "      <th>VOTSyllProp</th>\n",
       "      <th>VowSyllProp</th>\n",
       "      <th>F1OnsetFreq</th>\n",
       "      <th>F2OnsetFreq</th>\n",
       "      <th>ConSpace</th>\n",
       "      <th>...</th>\n",
       "      <th>RepVar_F1xF2Corr</th>\n",
       "      <th>RepVar_F1xF2Cov</th>\n",
       "      <th>RepVar_F1Ratio</th>\n",
       "      <th>RepVar_F2Ratio</th>\n",
       "      <th>RepVar_F1Vel</th>\n",
       "      <th>RepVar_F1Accel</th>\n",
       "      <th>RepVar_F1Jerk</th>\n",
       "      <th>RepVar_F2Vel</th>\n",
       "      <th>RepVar_F2Accel</th>\n",
       "      <th>RepVar_F2Jerk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>puh1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>1.0525</td>\n",
       "      <td>19.0476190476</td>\n",
       "      <td>0.950118764846</td>\n",
       "      <td>0.0498812351544</td>\n",
       "      <td>676.470107905</td>\n",
       "      <td>1027.22535907</td>\n",
       "      <td>350.755251163</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6946249773</td>\n",
       "      <td>18.4296956459</td>\n",
       "      <td>14.1973966519</td>\n",
       "      <td>37.92953917</td>\n",
       "      <td>-175.522685132</td>\n",
       "      <td>-330.575939957</td>\n",
       "      <td>626.730360288</td>\n",
       "      <td>205.407663144</td>\n",
       "      <td>-485.807256295</td>\n",
       "      <td>4644.89204335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tuh1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>1.0825</td>\n",
       "      <td>12.1212121212</td>\n",
       "      <td>0.923787528868</td>\n",
       "      <td>0.0762124711316</td>\n",
       "      <td>736.101404342</td>\n",
       "      <td>2016.97058248</td>\n",
       "      <td>1280.86917814</td>\n",
       "      <td>...</td>\n",
       "      <td>45.759997325</td>\n",
       "      <td>58.0635573838</td>\n",
       "      <td>62.4841644724</td>\n",
       "      <td>34.0034500126</td>\n",
       "      <td>-186.065848393</td>\n",
       "      <td>153.543788111</td>\n",
       "      <td>-260.838804984</td>\n",
       "      <td>-38.869139382</td>\n",
       "      <td>150.486878983</td>\n",
       "      <td>737.633364992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kuh1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.075</td>\n",
       "      <td>1.075</td>\n",
       "      <td>13.3333333333</td>\n",
       "      <td>0.93023255814</td>\n",
       "      <td>0.0697674418605</td>\n",
       "      <td>787.875712622</td>\n",
       "      <td>2159.11842067</td>\n",
       "      <td>1371.24270805</td>\n",
       "      <td>...</td>\n",
       "      <td>28.904989475</td>\n",
       "      <td>51.3132414576</td>\n",
       "      <td>18.2755762604</td>\n",
       "      <td>36.066672156</td>\n",
       "      <td>-417.911657211</td>\n",
       "      <td>132.463287072</td>\n",
       "      <td>-126.240637858</td>\n",
       "      <td>-29.7145422561</td>\n",
       "      <td>295.910040181</td>\n",
       "      <td>-107.727476251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puh2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1.0625</td>\n",
       "      <td>16</td>\n",
       "      <td>0.941176470588</td>\n",
       "      <td>0.0588235294118</td>\n",
       "      <td>921.313006474</td>\n",
       "      <td>1875.6304276</td>\n",
       "      <td>954.317421129</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6946249773</td>\n",
       "      <td>18.4296956459</td>\n",
       "      <td>14.1973966519</td>\n",
       "      <td>37.92953917</td>\n",
       "      <td>-175.522685132</td>\n",
       "      <td>-330.575939957</td>\n",
       "      <td>626.730360288</td>\n",
       "      <td>205.407663144</td>\n",
       "      <td>-485.807256295</td>\n",
       "      <td>4644.89204335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tuh2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>1.0875</td>\n",
       "      <td>11.4285714286</td>\n",
       "      <td>0.919540229885</td>\n",
       "      <td>0.0804597701149</td>\n",
       "      <td>1249.90610769</td>\n",
       "      <td>2372.41735058</td>\n",
       "      <td>1122.51124289</td>\n",
       "      <td>...</td>\n",
       "      <td>45.759997325</td>\n",
       "      <td>58.0635573838</td>\n",
       "      <td>62.4841644724</td>\n",
       "      <td>34.0034500126</td>\n",
       "      <td>-186.065848393</td>\n",
       "      <td>153.543788111</td>\n",
       "      <td>-260.838804984</td>\n",
       "      <td>-38.869139382</td>\n",
       "      <td>150.486878983</td>\n",
       "      <td>737.633364992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Task  VOT    Vow   Syll    VOTVowProp    VOTSyllProp     VowSyllProp  \\\n",
       "0  puh1    1 0.0525 1.0525 19.0476190476 0.950118764846 0.0498812351544   \n",
       "1  tuh1    1 0.0825 1.0825 12.1212121212 0.923787528868 0.0762124711316   \n",
       "2  kuh1    1  0.075  1.075 13.3333333333  0.93023255814 0.0697674418605   \n",
       "3  puh2    1 0.0625 1.0625            16 0.941176470588 0.0588235294118   \n",
       "4  tuh2    1 0.0875 1.0875 11.4285714286 0.919540229885 0.0804597701149   \n",
       "\n",
       "    F1OnsetFreq   F2OnsetFreq      ConSpace  ...  RepVar_F1xF2Corr  \\\n",
       "0 676.470107905 1027.22535907 350.755251163  ...     36.6946249773   \n",
       "1 736.101404342 2016.97058248 1280.86917814  ...      45.759997325   \n",
       "2 787.875712622 2159.11842067 1371.24270805  ...      28.904989475   \n",
       "3 921.313006474  1875.6304276 954.317421129  ...     36.6946249773   \n",
       "4 1249.90610769 2372.41735058 1122.51124289  ...      45.759997325   \n",
       "\n",
       "   RepVar_F1xF2Cov  RepVar_F1Ratio  RepVar_F2Ratio   RepVar_F1Vel  \\\n",
       "0    18.4296956459   14.1973966519     37.92953917 -175.522685132   \n",
       "1    58.0635573838   62.4841644724   34.0034500126 -186.065848393   \n",
       "2    51.3132414576   18.2755762604    36.066672156 -417.911657211   \n",
       "3    18.4296956459   14.1973966519     37.92953917 -175.522685132   \n",
       "4    58.0635573838   62.4841644724   34.0034500126 -186.065848393   \n",
       "\n",
       "   RepVar_F1Accel  RepVar_F1Jerk   RepVar_F2Vel  RepVar_F2Accel  RepVar_F2Jerk  \n",
       "0  -330.575939957  626.730360288  205.407663144  -485.807256295  4644.89204335  \n",
       "1   153.543788111 -260.838804984  -38.869139382   150.486878983  737.633364992  \n",
       "2   132.463287072 -126.240637858 -29.7145422561   295.910040181 -107.727476251  \n",
       "3  -330.575939957  626.730360288  205.407663144  -485.807256295  4644.89204335  \n",
       "4   153.543788111 -260.838804984  -38.869139382   150.486878983  737.633364992  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35f005cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Downloads/TRIAL_ACOUSTIC/FORMANT_Data_For_Spreadsheets.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = output_dir + \"FORMANT_Data_For_Spreadsheets.csv\"\n",
    "data.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6390d68",
   "metadata": {},
   "source": [
    "# ---------------- Spectrum Extraction Function ---------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a41486c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sound: Normal_Hannah_DDK, Duration=3.9564399092970524\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Task</th>\n",
       "      <th>Rep</th>\n",
       "      <th>CentralGravity</th>\n",
       "      <th>StandardDeviation</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal_Hannah_DDK</td>\n",
       "      <td>kuh</td>\n",
       "      <td>1</td>\n",
       "      <td>7352.90235621</td>\n",
       "      <td>4307.59188718</td>\n",
       "      <td>-0.113339745293</td>\n",
       "      <td>-1.19814190876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Normal_Hannah_DDK</td>\n",
       "      <td>kuh</td>\n",
       "      <td>2</td>\n",
       "      <td>7505.32800649</td>\n",
       "      <td>4273.48523805</td>\n",
       "      <td>0.0136717417364</td>\n",
       "      <td>-1.14369364794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Normal_Hannah_DDK</td>\n",
       "      <td>kuh</td>\n",
       "      <td>3</td>\n",
       "      <td>7568.83429639</td>\n",
       "      <td>4515.45146106</td>\n",
       "      <td>-0.0858927665585</td>\n",
       "      <td>-1.3844164423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal_Hannah_DDK</td>\n",
       "      <td>puh</td>\n",
       "      <td>1</td>\n",
       "      <td>5811.44137952</td>\n",
       "      <td>4000.62233161</td>\n",
       "      <td>0.536560026795</td>\n",
       "      <td>-0.739075985582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal_Hannah_DDK</td>\n",
       "      <td>puh</td>\n",
       "      <td>2</td>\n",
       "      <td>6458.85251923</td>\n",
       "      <td>5041.68593335</td>\n",
       "      <td>0.289631516679</td>\n",
       "      <td>-1.44782921203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Participant Task Rep  CentralGravity  StandardDeviation  \\\n",
       "2  Normal_Hannah_DDK  kuh   1   7352.90235621      4307.59188718   \n",
       "5  Normal_Hannah_DDK  kuh   2   7505.32800649      4273.48523805   \n",
       "8  Normal_Hannah_DDK  kuh   3   7568.83429639      4515.45146106   \n",
       "0  Normal_Hannah_DDK  puh   1   5811.44137952      4000.62233161   \n",
       "3  Normal_Hannah_DDK  puh   2   6458.85251923      5041.68593335   \n",
       "\n",
       "          Skewness        Kurtosis  \n",
       "2  -0.113339745293  -1.19814190876  \n",
       "5  0.0136717417364  -1.14369364794  \n",
       "8 -0.0858927665585   -1.3844164423  \n",
       "0   0.536560026795 -0.739075985582  \n",
       "3   0.289631516679  -1.44782921203  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- SPECTRUM Extraction Function ---------------- #\n",
    "\n",
    "# Energy threshold and padding\n",
    "ENERGY_THRESHOLD = 1e-5\n",
    "PAD_DURATION = 0.2  # Increased padding to 200ms\n",
    "\n",
    "# Manual pre-emphasis filter\n",
    "def manual_pre_emphasize(sound, alpha=0.97):\n",
    "    values = sound.values.flatten()\n",
    "    pre_emphasized_values = np.append(values[0], values[1:] - alpha * values[:-1])\n",
    "    sound.values[:] = pre_emphasized_values.reshape(sound.values.shape)\n",
    "    return sound\n",
    "\n",
    "# Prepare output DataFrame\n",
    "results = []\n",
    "\n",
    "# List all TextGrid files in the directory\n",
    "file_list = [f for f in os.listdir(project_dir) if f.endswith(\".TextGrid\")]\n",
    "\n",
    "for textgrid_file in file_list:\n",
    "    base_filename = os.path.splitext(textgrid_file)[0]\n",
    "    wav_file = os.path.join(project_dir, base_filename + \".wav\")\n",
    "    textgrid_path = os.path.join(project_dir, textgrid_file)\n",
    "\n",
    "    try:\n",
    "        sound = parselmouth.Sound(wav_file)\n",
    "        print(f\"Loaded sound: {base_filename}, Duration={sound.get_total_duration()}\")\n",
    "        tg = TextGrid()\n",
    "        tg.read(textgrid_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading sound or TextGrid for {textgrid_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    if len(tg.tiers) < 2:\n",
    "        print(f\"{textgrid_file} does not have enough tiers.\")\n",
    "        continue\n",
    "\n",
    "    consonant_tier = tg.tiers[1]\n",
    "\n",
    "    for interval in consonant_tier.intervals:\n",
    "        phoneme = interval.mark.strip()\n",
    "        if not phoneme:\n",
    "            continue\n",
    "\n",
    "        start_time = interval.minTime\n",
    "        end_time = interval.maxTime\n",
    "\n",
    "        if start_time >= end_time or (end_time - start_time) < 0.01:\n",
    "            continue\n",
    "\n",
    "        extended_start_time = max(0, start_time - PAD_DURATION)\n",
    "        extended_end_time = min(sound.xmax, end_time + PAD_DURATION)\n",
    "\n",
    "        try:\n",
    "            sound_interval = sound.extract_part(\n",
    "                from_time=extended_start_time,\n",
    "                to_time=extended_end_time,\n",
    "                window_shape=parselmouth.WindowShape.HAMMING,\n",
    "                preserve_times=True\n",
    "            )\n",
    "\n",
    "            if sound_interval is None or sound_interval.get_energy() < ENERGY_THRESHOLD:\n",
    "                continue\n",
    "\n",
    "            sound_interval.scale_intensity(70)\n",
    "            sound_preemphasized = manual_pre_emphasize(sound_interval)\n",
    "\n",
    "            if sound_preemphasized.get_total_duration() >= 0.05:\n",
    "                spectrum = sound_preemphasized.to_spectrum()\n",
    "                central_gravity = spectrum.get_centre_of_gravity(power=2)\n",
    "                std_deviation = spectrum.get_standard_deviation(power=2)\n",
    "                skewness = spectrum.get_skewness(power=2)\n",
    "                kurtosis = spectrum.get_kurtosis(power=2)\n",
    "\n",
    "                results.append([\n",
    "                    base_filename,  # Participant\n",
    "                    phoneme[0] + \"uh\",  # Convert short name to long name\n",
    "                    phoneme[1],  # Rep\n",
    "                    central_gravity,\n",
    "                    std_deviation,\n",
    "                    skewness,\n",
    "                    kurtosis\n",
    "                ])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {phoneme} in {textgrid_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "    \"Participant\", \"Task\", \"Rep\", \"CentralGravity\", \"StandardDeviation\", \"Skewness\", \"Kurtosis\"\n",
    "])\n",
    "\n",
    "# Reorder and save results\n",
    "output_rows = []\n",
    "for task in range(int(len(results_df) / 9)):\n",
    "    output_rows.append(results_df.iloc[task * 9 + 2])\n",
    "    output_rows.append(results_df.iloc[task * 9 + 5])\n",
    "    output_rows.append(results_df.iloc[task * 9 + 8])\n",
    "    output_rows.append(results_df.iloc[task * 9 + 0])\n",
    "    output_rows.append(results_df.iloc[task * 9 + 3])\n",
    "    output_rows.append(results_df.iloc[task * 9 + 6])\n",
    "    output_rows.append(results_df.iloc[task * 9 + 1])\n",
    "    output_rows.append(results_df.iloc[task * 9 + 4])\n",
    "    output_rows.append(results_df.iloc[task * 9 + 7])\n",
    "\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "#output_file = os.path.join(project_dir, \"Spectrum_Data_For_R.csv\")\n",
    "#output_df.to_csv(output_file, index=False)\n",
    "\n",
    "#print(f\"Reordered results saved to {output_file}\")\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73ec8b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Participant Task Rep  CentralGravity  StandardDeviation  \\\n",
      "2  Normal_Hannah_DDK  kuh   1   7352.90235621      4307.59188718   \n",
      "5  Normal_Hannah_DDK  kuh   2   7505.32800649      4273.48523805   \n",
      "8  Normal_Hannah_DDK  kuh   3   7568.83429639      4515.45146106   \n",
      "0  Normal_Hannah_DDK  puh   1   5811.44137952      4000.62233161   \n",
      "3  Normal_Hannah_DDK  puh   2   6458.85251923      5041.68593335   \n",
      "6  Normal_Hannah_DDK  puh   3   6935.55292005      4888.32020025   \n",
      "1  Normal_Hannah_DDK  tuh   1   6965.21012212      2532.45477894   \n",
      "4  Normal_Hannah_DDK  tuh   2   7020.79523745      2771.30407908   \n",
      "7  Normal_Hannah_DDK  tuh   3   7041.76438873      2566.29608184   \n",
      "\n",
      "          Skewness        Kurtosis  PhonVar_CentralGravity  \\\n",
      "2  -0.113339745293  -1.19814190876           801.830148522   \n",
      "5  0.0136717417364  -1.14369364794           523.714707367   \n",
      "8 -0.0858927665585   -1.3844164423           339.148164587   \n",
      "0   0.536560026795 -0.739075985582           801.830148522   \n",
      "3   0.289631516679  -1.44782921203           523.714707367   \n",
      "6   0.201998331592  -1.42359590573           339.148164587   \n",
      "1    0.46970889031   1.28590692998           801.830148522   \n",
      "4   0.369961181468  0.636101254286           523.714707367   \n",
      "7   0.630226410125  0.991139183097           339.148164587   \n",
      "\n",
      "   PhonVar_StandardDeviation  PhonVar_Skewness  PhonVar_Kurtosis  \\\n",
      "2              948.758664771    0.357487645401     1.32172841155   \n",
      "5              1154.79538641    0.186881788526      1.1256801295   \n",
      "8              1246.99864979    0.360344105648     1.38297656698   \n",
      "0              948.758664771    0.357487645401     1.32172841155   \n",
      "3              1154.79538641    0.186881788526      1.1256801295   \n",
      "6              1246.99864979    0.360344105648     1.38297656698   \n",
      "1              948.758664771    0.357487645401     1.32172841155   \n",
      "4              1154.79538641    0.186881788526      1.1256801295   \n",
      "7              1246.99864979    0.360344105648     1.38297656698   \n",
      "\n",
      "   RepVar_CentralGravity  RepVar_StandardDeviation  RepVar_Skewness  \\\n",
      "2          1.48448400056             3.00007407882    -108.04718503   \n",
      "5          1.48448400056             3.00007407882    -108.04718503   \n",
      "8          1.48448400056             3.00007407882    -108.04718503   \n",
      "0          8.81312900046             12.1037155997    50.6189221637   \n",
      "3          8.81312900046             12.1037155997    50.6189221637   \n",
      "6          8.81312900046             12.1037155997    50.6189221637   \n",
      "1          0.56439665159             4.92663608199     26.799791035   \n",
      "4          0.56439665159             4.92663608199     26.799791035   \n",
      "7          0.56439665159             4.92663608199     26.799791035   \n",
      "\n",
      "   RepVar_Kurtosis  \n",
      "2   -10.1630883153  \n",
      "5   -10.1630883153  \n",
      "8   -10.1630883153  \n",
      "0   -33.4346206934  \n",
      "3   -33.4346206934  \n",
      "6   -33.4346206934  \n",
      "1    33.5068886398  \n",
      "4    33.5068886398  \n",
      "7    33.5068886398  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 15)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- SPECTRUM Extraction Function R---------------- #\n",
    "\n",
    "# Read the original data\n",
    "spectrumData = output_df\n",
    "\n",
    "# Ensure numeric columns are numeric\n",
    "numeric_cols = [\"CentralGravity\", \"StandardDeviation\", \"Skewness\", \"Kurtosis\"]\n",
    "spectrumData[numeric_cols] = spectrumData[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Compute phoneme-level variation (PhonVar_*) per (Participant, Rep)\n",
    "grouped_pr = spectrumData.groupby([\"Participant\", \"Rep\"])\n",
    "spectrumData[\"PhonVar_CentralGravity\"] = grouped_pr[\"CentralGravity\"].transform(\"std\")\n",
    "spectrumData[\"PhonVar_StandardDeviation\"] = grouped_pr[\"StandardDeviation\"].transform(\"std\")\n",
    "spectrumData[\"PhonVar_Skewness\"] = grouped_pr[\"Skewness\"].transform(\"std\")\n",
    "spectrumData[\"PhonVar_Kurtosis\"] = grouped_pr[\"Kurtosis\"].transform(\"std\")\n",
    "\n",
    "# Function to compute the variation ratio for RepVar_*\n",
    "def variation_ratio(series):\n",
    "    mean_val = series.mean()\n",
    "    return ((series.std() / mean_val) * 100) if mean_val != 0 else 0\n",
    "\n",
    "# Compute repetition-level variation (RepVar_*) per (Participant, Task)\n",
    "grouped_pt = spectrumData.groupby([\"Participant\", \"Task\"])\n",
    "spectrumData[\"RepVar_CentralGravity\"] = grouped_pt[\"CentralGravity\"].transform(variation_ratio)\n",
    "spectrumData[\"RepVar_StandardDeviation\"] = grouped_pt[\"StandardDeviation\"].transform(variation_ratio)\n",
    "spectrumData[\"RepVar_Skewness\"] = grouped_pt[\"Skewness\"].transform(variation_ratio)\n",
    "spectrumData[\"RepVar_Kurtosis\"] = grouped_pt[\"Kurtosis\"].transform(variation_ratio)\n",
    "\n",
    "# Print the final DataFrame to the console\n",
    "print(spectrumData)\n",
    "spectrumData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4d7007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Participant  Task Rep  CentralGravity  StandardDeviation  \\\n",
      "2  Normal_Hannah_DDK  kuh1   1   7352.90235621      4307.59188718   \n",
      "5  Normal_Hannah_DDK  kuh2   2   7505.32800649      4273.48523805   \n",
      "8  Normal_Hannah_DDK  kuh3   3   7568.83429639      4515.45146106   \n",
      "0  Normal_Hannah_DDK  puh1   1   5811.44137952      4000.62233161   \n",
      "3  Normal_Hannah_DDK  puh2   2   6458.85251923      5041.68593335   \n",
      "\n",
      "          Skewness        Kurtosis  PhonVar_CentralGravity  \\\n",
      "2  -0.113339745293  -1.19814190876           801.830148522   \n",
      "5  0.0136717417364  -1.14369364794           523.714707367   \n",
      "8 -0.0858927665585   -1.3844164423           339.148164587   \n",
      "0   0.536560026795 -0.739075985582           801.830148522   \n",
      "3   0.289631516679  -1.44782921203           523.714707367   \n",
      "\n",
      "   PhonVar_StandardDeviation  PhonVar_Skewness  PhonVar_Kurtosis  \\\n",
      "2              948.758664771    0.357487645401     1.32172841155   \n",
      "5              1154.79538641    0.186881788526      1.1256801295   \n",
      "8              1246.99864979    0.360344105648     1.38297656698   \n",
      "0              948.758664771    0.357487645401     1.32172841155   \n",
      "3              1154.79538641    0.186881788526      1.1256801295   \n",
      "\n",
      "   RepVar_CentralGravity  RepVar_StandardDeviation  RepVar_Skewness  \\\n",
      "2          1.48448400056             3.00007407882    -108.04718503   \n",
      "5          1.48448400056             3.00007407882    -108.04718503   \n",
      "8          1.48448400056             3.00007407882    -108.04718503   \n",
      "0          8.81312900046             12.1037155997    50.6189221637   \n",
      "3          8.81312900046             12.1037155997    50.6189221637   \n",
      "\n",
      "   RepVar_Kurtosis  \n",
      "2   -10.1630883153  \n",
      "5   -10.1630883153  \n",
      "8   -10.1630883153  \n",
      "0   -33.4346206934  \n",
      "3   -33.4346206934  \n"
     ]
    }
   ],
   "source": [
    "# Append repetition numbers directly to the Task column\n",
    "spectrumData['Task'] = spectrumData['Task'] + (spectrumData.groupby('Task').cumcount() + 1).astype(str)\n",
    "\n",
    "# Verify the updated DataFrame\n",
    "print(spectrumData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6efd3ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Downloads/TRIAL_ACOUSTIC/Spectrum_Data_For_Spreadsheets.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = output_dir + \"Spectrum_Data_For_Spreadsheets.csv\"\n",
    "spectrumData.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827badd8",
   "metadata": {},
   "source": [
    "# ---------------- Duration Extraction Function ---------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06f53bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Participant   Task  Duration       DDKRate\n",
      "0  Normal_Hannah_DDK.TextGrid  puh_1   2.42935 3.70469467141\n"
     ]
    }
   ],
   "source": [
    "# DEFINE WHICH TIER TO ANALYZE\n",
    "tier_index = 3  # 4th tier (indexing starts at 0)\n",
    "\n",
    "# PREPARE DATA STORAGE\n",
    "results = []\n",
    "\n",
    "# Define a mapping for phonemes to specific task names\n",
    "phoneme_to_task = {\n",
    "    \"DDKrate\": \"puh\",  # Map all phonemes to specific tasks\n",
    "}\n",
    "\n",
    "# LOOP THROUGH EACH TEXTGRID FILE\n",
    "for tg_path in textgrid_files:\n",
    "    filename = os.path.basename(tg_path)\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    \n",
    "    # LOAD THE TEXTGRID\n",
    "    try:\n",
    "        tg = TextGrid.fromFile(tg_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")\n",
    "        continue\n",
    "    \n",
    "    # VALIDATE TIER INDEX\n",
    "    if tier_index >= len(tg.tiers):\n",
    "        print(f\"Tier index {tier_index} out of range for {filename}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    tier = tg.tiers[tier_index]\n",
    "    ddkrate_divisor = 9  # For full intervals\n",
    "    \n",
    "    # Track repetitions for each mapped task name\n",
    "    task_counts = {\n",
    "        \"puh\": 0,\n",
    "        \"tuh\": 0,\n",
    "        \"kuh\": 0,\n",
    "    }\n",
    "    \n",
    "    # LOOP THROUGH EACH INTERVAL IN THE SPECIFIED TIER\n",
    "    for interval in tier:\n",
    "        thisPhoneme = interval.mark.strip()\n",
    "        if thisPhoneme:  # Process non-empty labels\n",
    "            # Map the phoneme to a task name\n",
    "            task_name_base = phoneme_to_task.get(thisPhoneme, \"puh\")  # Default to \"puh\" if not mapped\n",
    "            \n",
    "            # Increment the repetition count for the task name\n",
    "            task_counts[task_name_base] += 1\n",
    "            \n",
    "            # Create the task name with repetition number\n",
    "            task_name = f\"{task_name_base}_{task_counts[task_name_base]}\"\n",
    "            \n",
    "            # Calculate duration and DDK rate\n",
    "            duration = interval.maxTime - interval.minTime\n",
    "            ddkrate = ddkrate_divisor / duration\n",
    "            \n",
    "            # Append result to the list\n",
    "            results.append({\n",
    "                \"Participant\": filename,\n",
    "                \"Task\": task_name,\n",
    "                \"Duration\": duration,\n",
    "                \"DDKRate\": ddkrate\n",
    "            })\n",
    "\n",
    "# CONVERT RESULTS TO DATAFRAME\n",
    "duration_df = pd.DataFrame(results)\n",
    "\n",
    "# DISPLAY OR EXPORT THE DATAFRAME\n",
    "print(duration_df.head())  # Preview the data\n",
    "#output_csv = os.path.join(project_dir, \"Duration_Data_For_R_2.csv\")\n",
    "#duration_df.to_csv(output_csv, index=False)  # Save to CSV if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8ee63e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 4)\n",
      "                  Participant  Task Duration             DDKRate\n",
      "0  Normal_Hannah_DDK.TextGrid  puh1  2.42935  3.7046946714141646\n",
      "1  Normal_Hannah_DDK.TextGrid  tuh1  2.42935  3.7046946714141646\n",
      "2  Normal_Hannah_DDK.TextGrid  kuh1  2.42935  3.7046946714141646\n",
      "3  Normal_Hannah_DDK.TextGrid  puh2  2.42935  3.7046946714141646\n",
      "4  Normal_Hannah_DDK.TextGrid  tuh2  2.42935  3.7046946714141646\n",
      "5  Normal_Hannah_DDK.TextGrid  kuh2  2.42935  3.7046946714141646\n",
      "6  Normal_Hannah_DDK.TextGrid  puh3  2.42935  3.7046946714141646\n",
      "7  Normal_Hannah_DDK.TextGrid  tuh3  2.42935  3.7046946714141646\n",
      "8  Normal_Hannah_DDK.TextGrid  kuh3  2.42935  3.7046946714141646\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the original DataFrame\n",
    "df = duration_df.copy()\n",
    "\n",
    "# Define the sequence of tasks\n",
    "task_sequence = [\"puh\", \"tuh\", \"kuh\"]\n",
    "\n",
    "# Expand the DataFrame to replicate each row 9 times\n",
    "df_expanded = df.loc[df.index.repeat(9)].reset_index(drop=True)\n",
    "\n",
    "# Add an alternating Task column (puh, tuh, kuh)\n",
    "df_expanded['Task'] = [\n",
    "    f\"{task}{i // 3 + 1}\" for i, task in enumerate(task_sequence * (len(df_expanded) // 3))\n",
    "]\n",
    "\n",
    "# Convert all columns to string if needed\n",
    "df_expanded = df_expanded.astype(str)\n",
    "\n",
    "# Display the expanded DataFrame\n",
    "print(df_expanded.shape)\n",
    "print(df_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e87ba522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Downloads/TRIAL_ACOUSTIC/Duration_Data_For_Spreadsheets.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = output_dir + \"Duration_Data_For_Spreadsheets.csv\"\n",
    "df_expanded.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ce9b6",
   "metadata": {},
   "source": [
    "# ---------------- Ratio Extraction Function ---------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6383511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Participant Rep Task  BurstToBurst  DurationRatio    DistanceFrom1\n",
      "0  Normal_Hannah_DDK   1  kuh       0.30006 0.939462920149 -0.0605370798506\n",
      "1  Normal_Hannah_DDK   1  puh       0.26413 0.939462920149 -0.0605370798506\n",
      "2  Normal_Hannah_DDK   1  tuh       0.28115 0.939462920149 -0.0605370798506\n",
      "3  Normal_Hannah_DDK   2  kuh       0.29529 0.947940975837 -0.0520590241626\n",
      "4  Normal_Hannah_DDK   2  puh       0.26403 0.947940975837 -0.0520590241626\n",
      "5  Normal_Hannah_DDK   2  tuh       0.27853 0.947940975837 -0.0520590241626\n",
      "6  Normal_Hannah_DDK   3  kuh       0.30468  1.00967827303 0.00967827303316\n",
      "7  Normal_Hannah_DDK   3  puh       0.26707  1.00967827303 0.00967827303316\n",
      "8  Normal_Hannah_DDK   3  tuh       0.26451  1.00967827303 0.00967827303316\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty dataframe\n",
    "ratio_data = pd.DataFrame(columns=[\"Participant\", \"Task\", \"Time\", \"F1\", \"F2\", \"Duration\"])\n",
    "\n",
    "# Loop through the TextGrid files\n",
    "for file in textgrid_files:\n",
    "    file_path = os.path.join(project_dir, file)\n",
    "    sound_file = file_path.replace(\".TextGrid\", \".wav\")\n",
    "    \n",
    "    try:\n",
    "        tg = TextGrid.fromFile(file_path)\n",
    "        snd = parselmouth.Sound(sound_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files: {e}\")\n",
    "        continue\n",
    "\n",
    "    tier_name = \"vowel\"  # Replace with your specific tier name\n",
    "    tier = next((t for t in tg.tiers if t.name == tier_name), None)\n",
    "\n",
    "    if tier is None:\n",
    "        print(f\"Tier '{tier_name}' not found in TextGrid {file}\")\n",
    "        continue\n",
    "\n",
    "    formant = snd.to_formant_burg(time_step=0.01, max_number_of_formants=5, maximum_formant=5000)\n",
    "\n",
    "    new_rows = []\n",
    "    for interval in tier.intervals:\n",
    "        label = interval.mark.strip()\n",
    "        start_time, end_time = interval.minTime, interval.maxTime\n",
    "        if label:\n",
    "            duration = end_time - start_time\n",
    "            frame_count = int(duration / 0.0025)\n",
    "            \n",
    "            for frame in range(frame_count):\n",
    "                frame_time = start_time + (frame * 0.0025)\n",
    "                f1 = formant.get_value_at_time(1, frame_time)\n",
    "                f2 = formant.get_value_at_time(2, frame_time)\n",
    "                \n",
    "                new_rows.append({\n",
    "                    \"Participant\": \"Normal_Hannah_DDK\",\n",
    "                    \"Task\": label,\n",
    "                    \"Time\": frame_time,\n",
    "                    \"F1\": f1,\n",
    "                    \"F2\": f2,\n",
    "                    \"Duration\": duration\n",
    "                })\n",
    "    \n",
    "    ratio_data = pd.concat([ratio_data, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "# Processing ratio_data to compute BurstToBurst and DurationRatios\n",
    "current_pt = ratio_data[\"Participant\"].iloc[0]\n",
    "previous_pt = ratio_data[\"Participant\"].iloc[0]\n",
    "current_task = ratio_data[\"Task\"].iloc[0]\n",
    "previous_task = ratio_data[\"Task\"].iloc[0]\n",
    "VOT_start = ratio_data[\"Time\"].iloc[0]  \n",
    "current_time = 0\n",
    "previous_time = 0\n",
    "table_row = 0\n",
    "\n",
    "ratio_table = pd.DataFrame(columns=[\"Participant\", \"Rep\", \"Task\", \"BurstToBurst\"])\n",
    "\n",
    "kuh1gap = kuh2gap = 0\n",
    "\n",
    "for index, row in ratio_data.iterrows():\n",
    "    current_pt = row[\"Participant\"]\n",
    "    current_task = row[\"Task\"]\n",
    "    current_time = row[\"Time\"]\n",
    "    \n",
    "    if current_task == \"p2VOT\" and previous_task == \"kuh1\":\n",
    "        kuh1gap = current_time - previous_time\n",
    "    if current_task == \"p3VOT\" and previous_task == \"kuh2\":\n",
    "        kuh2gap = current_time - previous_time\n",
    "    \n",
    "    if current_task != previous_task and \"VOT\" in current_task and \"p1VOT\" not in current_task:\n",
    "        burst_to_burst = current_time - VOT_start\n",
    "        ratio_table.loc[table_row] = [previous_pt, \"\", previous_task, burst_to_burst]\n",
    "        table_row += 1\n",
    "        VOT_start = current_time\n",
    "\n",
    "    if (index == len(ratio_data) - 1) or (current_task == \"p1VOT\" and previous_task == \"kuh3\"):\n",
    "        if index == len(ratio_data) - 1:\n",
    "            last_kuh = row[\"Time\"]\n",
    "            kuh_pt = current_pt\n",
    "        else:\n",
    "            last_kuh = previous_time\n",
    "            kuh_pt = previous_pt\n",
    "        burst_to_burst = last_kuh - VOT_start + (kuh1gap + kuh2gap) / 2\n",
    "        ratio_table.loc[table_row] = [kuh_pt, \"\", \"kuh3\", burst_to_burst]\n",
    "        table_row += 1\n",
    "        VOT_start = current_time\n",
    "\n",
    "    previous_pt = current_pt\n",
    "    previous_task = current_task\n",
    "    previous_time = current_time\n",
    "\n",
    "ratio_table[\"BurstToBurst\"] = ratio_table[\"BurstToBurst\"].astype(float)\n",
    "ratio_table[\"DurationRatio\"] = None\n",
    "for i in range(2, len(ratio_table), 3):\n",
    "    duration_ratio = ratio_table.loc[i - 2, \"BurstToBurst\"] / ratio_table.loc[i - 1, \"BurstToBurst\"]\n",
    "    ratio_table.loc[i - 2:i, \"DurationRatio\"] = duration_ratio\n",
    "\n",
    "task_mapping = {\"p1VOT\": \"puh1\", \"t1VOT\": \"tuh1\", \"k1VOT\": \"kuh1\",\n",
    "                \"p2VOT\": \"puh2\", \"t2VOT\": \"tuh2\", \"k2VOT\": \"kuh2\",\n",
    "                \"p3VOT\": \"puh3\", \"t3VOT\": \"tuh3\", \"k3VOT\": \"kuh3\"}\n",
    "ratio_table[\"Task\"] = ratio_table[\"Task\"].replace(task_mapping)\n",
    "\n",
    "ratio_table[\"Rep\"] = ratio_table[\"Task\"].str.extract(r'(\\d)').fillna(\"\")\n",
    "ratio_table[\"Task\"] = ratio_table[\"Task\"].str.replace(r'\\d', '', regex=True)\n",
    "\n",
    "for i in range(2, len(ratio_table), 3):\n",
    "    ratio_table.iloc[i - 2:i + 1] = ratio_table.iloc[[i, i - 2, i - 1]].values\n",
    "\n",
    "ratio_table[\"DistanceFrom1\"] = ratio_table[\"DurationRatio\"].astype(float) - 1\n",
    "\n",
    "ratio_table = ratio_table[[\"Participant\", \"Rep\", \"Task\", \"BurstToBurst\", \"DurationRatio\", \"DistanceFrom1\"]]\n",
    "\n",
    "print(ratio_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "395648b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Participant Rep  Task  BurstToBurst  DurationRatio    DistanceFrom1\n",
      "0  Normal_Hannah_DDK   1  kuh1       0.30006 0.939462920149 -0.0605370798506\n",
      "1  Normal_Hannah_DDK   1  puh1       0.26413 0.939462920149 -0.0605370798506\n",
      "2  Normal_Hannah_DDK   1  tuh1       0.28115 0.939462920149 -0.0605370798506\n",
      "3  Normal_Hannah_DDK   2  kuh2       0.29529 0.947940975837 -0.0520590241626\n",
      "4  Normal_Hannah_DDK   2  puh2       0.26403 0.947940975837 -0.0520590241626\n"
     ]
    }
   ],
   "source": [
    "# Append repetition numbers directly to the Task column\n",
    "ratio_table['Task'] = ratio_table['Task'] + (ratio_table.groupby('Task').cumcount() + 1).astype(str)\n",
    "\n",
    "# Verify the updated DataFrame\n",
    "print(ratio_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "39b5cda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Downloads/TRIAL_ACOUSTIC/Ratio_Data_For_Spreadsheets.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = output_dir + \"Ratio_Data_For_Spreadsheets.csv\"\n",
    "ratio_table.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b1a3e",
   "metadata": {},
   "source": [
    "# ---------------- Gap Extraction Function ---------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "854d01db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Participant Task     Gap Rep\n",
      "2  Normal_Hannah_DDK  kuh  0.0845   1\n",
      "0  Normal_Hannah_DDK  puh 0.07532   1\n",
      "1  Normal_Hannah_DDK  tuh 0.05335   1\n",
      "5  Normal_Hannah_DDK  kuh 0.10174   2\n",
      "3  Normal_Hannah_DDK  puh 0.08937   2\n",
      "4  Normal_Hannah_DDK  tuh 0.04672   2\n",
      "8  Normal_Hannah_DDK  kuh       0   3\n",
      "6  Normal_Hannah_DDK  puh 0.08889   3\n",
      "7  Normal_Hannah_DDK  tuh 0.07382   3\n",
      "Results saved to Downloads/TRIAL_ACOUSTIC/GAP_Data_For_Spreadsheets.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty dataframe\n",
    "gap_data = pd.DataFrame(columns=[\"Participant\", \"Task\", \"Time\", \"F1\", \"F2\", \"Duration\"])\n",
    "\n",
    "# Loop through the TextGrid files\n",
    "for file in textgrid_files:\n",
    "    file_path = os.path.join(project_dir, file)\n",
    "    sound_file = file_path.replace(\".TextGrid\", \".wav\")\n",
    "    \n",
    "    try:\n",
    "        tg = TextGrid.fromFile(file_path)\n",
    "        snd = parselmouth.Sound(sound_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files: {e}\")\n",
    "        continue\n",
    "\n",
    "    tier_name = \"vowel\"  # Replace with your specific tier name\n",
    "    tier = next((t for t in tg.tiers if t.name == tier_name), None)\n",
    "\n",
    "    if tier is None:\n",
    "        print(f\"Tier '{tier_name}' not found in TextGrid {file}\")\n",
    "        continue\n",
    "\n",
    "    formant = snd.to_formant_burg(time_step=0.01, max_number_of_formants=5, maximum_formant=5000)\n",
    "\n",
    "    new_rows = []\n",
    "    for interval in tier.intervals:\n",
    "        label = interval.mark.strip()\n",
    "        start_time, end_time = interval.minTime, interval.maxTime\n",
    "        if label:\n",
    "            duration = end_time - start_time\n",
    "            frame_count = int(duration / 0.0025)\n",
    "            \n",
    "            for frame in range(frame_count):\n",
    "                frame_time = start_time + (frame * 0.0025)\n",
    "                f1 = formant.get_value_at_time(1, frame_time)\n",
    "                f2 = formant.get_value_at_time(2, frame_time)\n",
    "                \n",
    "                new_rows.append({\n",
    "                    \"Participant\": \"Normal_Hannah_DDK\",\n",
    "                    \"Task\": label,\n",
    "                    \"Time\": frame_time,\n",
    "                    \"F1\": f1,\n",
    "                    \"F2\": f2,\n",
    "                    \"Duration\": duration\n",
    "                })\n",
    "    \n",
    "    gap_data = pd.concat([gap_data, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "# Processing gap_data to compute Gap durations\n",
    "current_pt = gap_data[\"Participant\"].iloc[0]\n",
    "previous_pt = gap_data[\"Participant\"].iloc[0]\n",
    "current_task = gap_data[\"Task\"].iloc[0]\n",
    "previous_task = gap_data[\"Task\"].iloc[0]\n",
    "current_time = 0\n",
    "previous_time = gap_data[\"Time\"].iloc[0]\n",
    "table_row = 0\n",
    "\n",
    "gap_table = pd.DataFrame(columns=[\"Participant\", \"Task\", \"Gap\"])\n",
    "\n",
    "kuh1gap = kuh2gap = None\n",
    "\n",
    "for index, row in gap_data.iterrows():\n",
    "    current_pt = row[\"Participant\"]\n",
    "    current_task = row[\"Task\"]\n",
    "    current_time = row[\"Time\"]\n",
    "    \n",
    "    if current_task == \"p2vot\" and previous_task == \"kuh1\":\n",
    "        kuh1gap = current_time - previous_time\n",
    "    if current_task == \"p3vot\" and previous_task == \"kuh2\":\n",
    "        kuh2gap = current_time - previous_time\n",
    "    \n",
    "    if current_task != previous_task and \"vot\" in current_task.lower() and \"p1vot\" not in current_task.lower():\n",
    "        gap = current_time - previous_time\n",
    "        gap_table.loc[table_row] = [previous_pt, previous_task, gap]\n",
    "        table_row += 1\n",
    "    \n",
    "    if index == len(gap_data) - 1 or (current_task == \"p1vot\" and previous_task == \"kuh3\"):\n",
    "        kuh1gap = kuh1gap if kuh1gap else 0\n",
    "        kuh2gap = kuh2gap if kuh2gap else 0\n",
    "        gap = np.mean([kuh1gap, kuh2gap]) if kuh1gap and kuh2gap else 0\n",
    "        gap_table.loc[table_row] = [current_pt, \"kuh3\", gap]\n",
    "        table_row += 1\n",
    "\n",
    "    previous_pt = current_pt\n",
    "    previous_task = current_task\n",
    "    previous_time = current_time\n",
    "\n",
    "# Add Rep column\n",
    "gap_table[\"Rep\"] = gap_table[\"Task\"].apply(lambda x: re.search(r\"(\\d)\", x).group() if re.search(r\"(\\d)\", x) else None)\n",
    "\n",
    "# Remove numbers from task names\n",
    "gap_table[\"Task\"] = gap_table[\"Task\"].str.replace(r'\\d$', '', regex=True)\n",
    "\n",
    "def reorder_rows(df):\n",
    "    reordered = []\n",
    "    for i in range(0, len(df), 3):\n",
    "        if i + 2 < len(df):\n",
    "            reordered.append(df.iloc[i + 2])\n",
    "            reordered.append(df.iloc[i])\n",
    "            reordered.append(df.iloc[i + 1])\n",
    "    return pd.DataFrame(reordered)\n",
    "\n",
    "gap_table = reorder_rows(gap_table)\n",
    "\n",
    "print(gap_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c040c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Participant  Task     Gap Rep\n",
      "2  Normal_Hannah_DDK  kuh1  0.0845   1\n",
      "0  Normal_Hannah_DDK  puh1 0.07532   1\n",
      "1  Normal_Hannah_DDK  tuh1 0.05335   1\n",
      "5  Normal_Hannah_DDK  kuh2 0.10174   2\n",
      "3  Normal_Hannah_DDK  puh2 0.08937   2\n"
     ]
    }
   ],
   "source": [
    "# Append repetition numbers directly to the Task column\n",
    "gap_table['Task'] = gap_table['Task'] + (gap_table.groupby('Task').cumcount() + 1).astype(str)\n",
    "\n",
    "# Verify the updated DataFrame\n",
    "print(gap_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c15d1cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Downloads/TRIAL_ACOUSTIC/GAP_Data_For_Spreadsheets.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = output_dir + \"GAP_Data_For_Spreadsheets.csv\"\n",
    "spectrumData.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bc259",
   "metadata": {},
   "source": [
    "## CONSOLIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ca7b48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Formant dataset with shape: (9, 82)\n",
      "Loaded Spectrum dataset with shape: (9, 15)\n",
      "Loaded Duration dataset with shape: (9, 4)\n",
      "Loaded Gap dataset with shape: (9, 15)\n",
      "Loaded Ratio dataset with shape: (9, 6)\n",
      "Final merged dataset shape: (9, 118)\n",
      "   Task  VOT    Vow   Syll    VOTVowProp    VOTSyllProp     VowSyllProp  \\\n",
      "0  puh1    1 0.0525 1.0525 19.0476190476 0.950118764846 0.0498812351544   \n",
      "1  tuh1    1 0.0825 1.0825 12.1212121212 0.923787528868 0.0762124711316   \n",
      "2  kuh1    1  0.075  1.075 13.3333333333  0.93023255814 0.0697674418605   \n",
      "3  puh2    1 0.0625 1.0625            16 0.941176470588 0.0588235294118   \n",
      "4  tuh2    1 0.0875 1.0875 11.4285714286 0.919540229885 0.0804597701149   \n",
      "\n",
      "    F1OnsetFreq   F2OnsetFreq      ConSpace  ...  PhonVar_Kurtosis_Gap  \\\n",
      "0 676.470107905 1027.22535907 350.755251163  ...         1.32172841155   \n",
      "1 736.101404342 2016.97058248 1280.86917814  ...         1.32172841155   \n",
      "2 787.875712622 2159.11842067 1371.24270805  ...         1.32172841155   \n",
      "3 921.313006474  1875.6304276 954.317421129  ...          1.1256801295   \n",
      "4 1249.90610769 2372.41735058 1122.51124289  ...          1.1256801295   \n",
      "\n",
      "   RepVar_CentralGravity_Gap  RepVar_StandardDeviation_Gap  \\\n",
      "0              8.81312900046                 12.1037155997   \n",
      "1              0.56439665159                 4.92663608199   \n",
      "2              1.48448400056                 3.00007407882   \n",
      "3              8.81312900046                 12.1037155997   \n",
      "4              0.56439665159                 4.92663608199   \n",
      "\n",
      "   RepVar_Skewness_Gap  RepVar_Kurtosis_Gap  Participant_Ratio  Rep_Ratio  \\\n",
      "0        50.6189221637       -33.4346206934  Normal_Hannah_DDK          1   \n",
      "1         26.799791035        33.5068886398  Normal_Hannah_DDK          1   \n",
      "2        -108.04718503       -10.1630883153  Normal_Hannah_DDK          1   \n",
      "3        50.6189221637       -33.4346206934  Normal_Hannah_DDK          2   \n",
      "4         26.799791035        33.5068886398  Normal_Hannah_DDK          2   \n",
      "\n",
      "   BurstToBurst  DurationRatio    DistanceFrom1  \n",
      "0       0.26413 0.939462920149 -0.0605370798506  \n",
      "1       0.28115 0.939462920149 -0.0605370798506  \n",
      "2       0.30006 0.939462920149 -0.0605370798506  \n",
      "3       0.26403 0.947940975837 -0.0520590241626  \n",
      "4       0.27853 0.947940975837 -0.0520590241626  \n",
      "\n",
      "[5 rows x 118 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the relevant files for merging\n",
    "files_to_merge = {\n",
    "    \"Formant\": \"FORMANT_Data_For_Spreadsheets.csv\",\n",
    "    \"Spectrum\": \"Spectrum_Data_For_Spreadsheets.csv\",\n",
    "    \"Duration\": \"Duration_Data_For_Spreadsheets.csv\",\n",
    "    \"Gap\": \"GAP_Data_For_Spreadsheets.csv\",\n",
    "    \"Ratio\": \"Ratio_Data_For_Spreadsheets.csv\"\n",
    "}\n",
    "\n",
    "# Load datasets into a dictionary\n",
    "dataframes = {}\n",
    "for name, file in files_to_merge.items():\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Validate \"Task\" column\n",
    "        if \"Task\" not in df.columns:\n",
    "            raise ValueError(f\"'Task' column not found in {name} dataset.\")\n",
    "        dataframes[name] = df\n",
    "        print(f\"Loaded {name} dataset with shape: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"File not found: {file}\")\n",
    "\n",
    "# Ensure all datasets have the same unique \"Task\" values\n",
    "common_tasks = set.intersection(*(set(df[\"Task\"]) for df in dataframes.values()))\n",
    "if len(common_tasks) != 9:\n",
    "    raise ValueError(f\"Inconsistent 'Task' values across datasets. Common tasks: {len(common_tasks)}\")\n",
    "\n",
    "# Filter datasets to only include common \"Task\" values\n",
    "for name, df in dataframes.items():\n",
    "    dataframes[name] = df[df[\"Task\"].isin(common_tasks)]\n",
    "\n",
    "# Merge datasets using \"Task\" as the key column\n",
    "merged_df = dataframes[\"Formant\"]  # Start with the Formant dataset\n",
    "for name, df in dataframes.items():\n",
    "    if name != \"Formant\":  # Skip the Formant dataset as it is already loaded\n",
    "        merged_df = pd.merge(merged_df, df, on=\"Task\", how=\"inner\", suffixes=(\"\", f\"_{name}\"))\n",
    "\n",
    "# Display the resulting merged dataframe\n",
    "print(\"Final merged dataset shape:\", merged_df.shape)\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b9a91a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 118)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b39d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
